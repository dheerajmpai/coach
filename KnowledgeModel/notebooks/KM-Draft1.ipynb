{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "gpuClass": "standard",
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "6999mXBSEoHl"
      },
      "outputs": [],
      "source": [
        "import argparse\n",
        "from collections import defaultdict, namedtuple\n",
        "from io import open\n",
        "import math\n",
        "import os\n",
        "from random import shuffle, uniform\n",
        "from datetime import datetime\n",
        "from future.utils import iterkeys, iteritems\n",
        "import torch\n",
        "\n",
        "from future.builtins import range\n",
        "from future.utils import iteritems\n",
        "import pickle\n",
        "import numpy as np\n",
        "from torch.nn.utils.rnn import pad_sequence, pack_padded_sequence, pad_packed_sequence"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# !pip install scipy\n",
        "# !pip install matplotlib\n",
        "# !pip install sklearn\n",
        "!pip install torchsummaryX -q\n",
        "from torchsummaryX import summary"
      ],
      "metadata": {
        "id": "kQUs_FYrHQEO"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import gc"
      ],
      "metadata": {
        "id": "sOY6ysWQ1EwA"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'"
      ],
      "metadata": {
        "id": "VmO3lJnO23IR"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Get Glove Vectors\n",
        "!wget https://nlp.stanford.edu/data/glove.6B.zip\n",
        "!unzip /content/glove.6B.zip"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t6PvbACjSGzA",
        "outputId": "da59ce1a-8319-43e9-ddc1-87005052661f"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2023-04-07 04:56:56--  https://nlp.stanford.edu/data/glove.6B.zip\n",
            "Resolving nlp.stanford.edu (nlp.stanford.edu)... 171.64.67.140\n",
            "Connecting to nlp.stanford.edu (nlp.stanford.edu)|171.64.67.140|:443... connected.\n",
            "HTTP request sent, awaiting response... 301 Moved Permanently\n",
            "Location: https://downloads.cs.stanford.edu/nlp/data/glove.6B.zip [following]\n",
            "--2023-04-07 04:56:56--  https://downloads.cs.stanford.edu/nlp/data/glove.6B.zip\n",
            "Resolving downloads.cs.stanford.edu (downloads.cs.stanford.edu)... 171.64.64.22\n",
            "Connecting to downloads.cs.stanford.edu (downloads.cs.stanford.edu)|171.64.64.22|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 862182613 (822M) [application/zip]\n",
            "Saving to: ‘glove.6B.zip’\n",
            "\n",
            "glove.6B.zip        100%[===================>] 822.24M  5.00MB/s    in 2m 39s  \n",
            "\n",
            "2023-04-07 04:59:35 (5.19 MB/s) - ‘glove.6B.zip’ saved [862182613/862182613]\n",
            "\n",
            "Archive:  /content/glove.6B.zip\n",
            "  inflating: glove.6B.50d.txt        \n",
            "  inflating: glove.6B.100d.txt       \n",
            "  inflating: glove.6B.200d.txt       \n",
            "  inflating: glove.6B.300d.txt       \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Prepare Glove Vectors\n",
        "word2vec = {}\n",
        "with open(\"/content/glove.6B.50d.txt\", 'r', encoding=\"utf-8\") as f:\n",
        "    for l in f:\n",
        "        line = l.split()\n",
        "        word = line[0]\n",
        "        vect = np.array(line[1:]).astype(float)\n",
        "        word2vec[word] = vect\n",
        "pickle.dump(word2vec, open(f'/content/6B.50_word2Vec.pkl', 'wb'))"
      ],
      "metadata": {
        "id": "O5UWvnXoSJFH"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Data Loading Utilities"
      ],
      "metadata": {
        "id": "XV93xsMXSVzt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class InstanceData(object):\n",
        "    \"\"\"\n",
        "    A bare-bones class to store the included properties of each instance. This is meant to act as easy access to the\n",
        "    data, and provides a launching point for deriving your own features from the data.\n",
        "    \"\"\"\n",
        "    def __init__(self, instance_properties):\n",
        "\n",
        "        # Parameters specific to this instance\n",
        "        self.instance_id = instance_properties['instance_id']\n",
        "        self.token = instance_properties['token']\n",
        "        self.part_of_speech = instance_properties['part_of_speech']\n",
        "        self.morphological_features = instance_properties['morphological_features']\n",
        "        self.dependency_label = instance_properties['dependency_label']\n",
        "        self.dependency_edge_head = instance_properties['dependency_edge_head']\n",
        "\n",
        "        # Derived parameters specific to this instance\n",
        "        self.exercise_index = int(self.instance_id[8:10])\n",
        "        self.token_index = int(self.instance_id[10:12])\n",
        "\n",
        "        # Derived parameters specific to this exercise\n",
        "        self.exercise_id = self.instance_id[:10]\n",
        "\n",
        "        # Parameters shared across the whole session\n",
        "        self.user = instance_properties['user']\n",
        "        self.countries = instance_properties['countries']\n",
        "        self.days = instance_properties['days']\n",
        "        self.client = instance_properties['client']\n",
        "        self.session = instance_properties['session']\n",
        "        self.format = instance_properties['format']\n",
        "        self.time = instance_properties['time']\n",
        "        self.prompt = instance_properties.get('prompt', None)\n",
        "\n",
        "        # Derived parameters shared across the whole session\n",
        "        self.session_id = self.instance_id[:8]\n",
        "\n",
        "    def to_features(self):\n",
        "        \"\"\"\n",
        "        Prepares those features that we wish to use in the LogisticRegression example in this file. We introduce a bias,\n",
        "        and take a few included features to use. Note that this dict restructures the corresponding features of the\n",
        "        input dictionary, 'instance_properties'.\n",
        "\n",
        "        Returns:\n",
        "            to_return: a representation of the features we'll use for logistic regression in a dict. A key/feature is a\n",
        "                key/value pair of the original 'instance_properties' dict, and we encode this feature as 1.0 for 'hot'.\n",
        "        \"\"\"\n",
        "        to_return = dict()\n",
        "\n",
        "        to_return['bias'] = 1.0\n",
        "        to_return['user:' + self.user] = 1.0\n",
        "        to_return['format:' + self.format] = 1.0\n",
        "        to_return['token:' + self.token.lower()] = 1.0\n",
        "\n",
        "        to_return['part_of_speech:' + self.part_of_speech] = 1.0\n",
        "        for morphological_feature in self.morphological_features:\n",
        "            to_return['morphological_feature:' + morphological_feature] = 1.0\n",
        "        to_return['dependency_label:' + self.dependency_label] = 1.0\n",
        "        \n",
        "        time = datetime.now()\n",
        "        if(time.second %10 == 0 and time.microsecond == 0):\n",
        "          print(time)\n",
        "          \n",
        "        return to_return"
      ],
      "metadata": {
        "id": "r1dTGVEBSU6a"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Load data from the file\n",
        "def load_data(filename):\n",
        "    \"\"\"\n",
        "    This method loads and returns the data in filename. If the data is labelled training data, it returns labels too.\n",
        "\n",
        "    Parameters:\n",
        "        filename: the location of the training or test data you want to load.\n",
        "\n",
        "    Returns:\n",
        "        data: a list of InstanceData objects from that data type and track.\n",
        "        labels (optional): if you specified training data, a dict of instance_id:label pairs.\n",
        "    \"\"\"\n",
        "\n",
        "    # 'data' stores a list of 'InstanceData's as values.\n",
        "    data = []\n",
        "\n",
        "    # If this is training data, then 'labels' is a dict that contains instance_ids as keys and labels as values.\n",
        "    training = False\n",
        "    if filename.find('train') != -1:\n",
        "        training = True\n",
        "\n",
        "    if training:\n",
        "        labels = dict()\n",
        "\n",
        "    num_exercises = 0\n",
        "    print('Loading instances...')\n",
        "    instance_properties = dict()\n",
        "\n",
        "    with open(filename, 'rt') as f:\n",
        "        for line in f:\n",
        "            line = line.strip()\n",
        "\n",
        "            # If there's nothing in the line, then we're done with the exercise. Print if needed, otherwise continue\n",
        "            if len(line) == 0:\n",
        "                num_exercises += 1\n",
        "                if num_exercises % 100000 == 0:\n",
        "                    print('Loaded ' + str(len(data)) + ' instances across ' + str(num_exercises) + ' exercises...')\n",
        "                instance_properties = dict()\n",
        "\n",
        "            # If the line starts with #, then we're beginning a new exercise\n",
        "            elif line[0] == '#':\n",
        "                if 'prompt' in line:\n",
        "                    instance_properties['prompt'] = line.split(':')[1]\n",
        "                else:\n",
        "                    list_of_exercise_parameters = line[2:].split()\n",
        "                    for exercise_parameter in list_of_exercise_parameters:\n",
        "                        [key, value] = exercise_parameter.split(':')\n",
        "                        if key == 'countries':\n",
        "                            value = value.split('|')\n",
        "                        elif key == 'days':\n",
        "                            value = float(value)\n",
        "                        elif key == 'time':\n",
        "                            if value == 'null':\n",
        "                                value = None\n",
        "                            else:\n",
        "                                assert '.' not in value\n",
        "                                value = int(value)\n",
        "                        instance_properties[key] = value\n",
        "\n",
        "            # Otherwise we're parsing a new Instance for the current exercise\n",
        "            else:\n",
        "                line = line.split()\n",
        "                if training:\n",
        "                    assert len(line) == 7\n",
        "                else:\n",
        "                    assert len(line) == 6\n",
        "                assert len(line[0]) == 12\n",
        "\n",
        "                instance_properties['instance_id'] = line[0]\n",
        "\n",
        "                instance_properties['token'] = line[1]\n",
        "                instance_properties['part_of_speech'] = line[2]\n",
        "\n",
        "                instance_properties['morphological_features'] = dict()\n",
        "                for l in line[3].split('|'):\n",
        "                    [key, value] = l.split('=')\n",
        "                    if key == 'Person':\n",
        "                        value = int(value)\n",
        "                    instance_properties['morphological_features'][key] = value\n",
        "\n",
        "                instance_properties['dependency_label'] = line[4]\n",
        "                instance_properties['dependency_edge_head'] = int(line[5])\n",
        "                if training:\n",
        "                    label = float(line[6])\n",
        "                    labels[instance_properties['instance_id']] = label\n",
        "                data.append(InstanceData(instance_properties=instance_properties))\n",
        "\n",
        "        print('Done loading ' + str(len(data)) + ' instances across ' + str(num_exercises) +\n",
        "              ' exercises.\\n')\n",
        "\n",
        "    if training:\n",
        "        return data, labels\n",
        "    else:\n",
        "        return data"
      ],
      "metadata": {
        "id": "ZYZ_49knNvCh"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def load_labels(filename):\n",
        "    \"\"\"\n",
        "    This loads labels, either the actual ones or your predictions.\n",
        "\n",
        "    Parameters:\n",
        "        filename: the filename pointing to your labels\n",
        "\n",
        "    Returns:\n",
        "        labels: a dict of instance_ids as keys and labels between 0 and 1 as values\n",
        "    \"\"\"\n",
        "    labels = dict()\n",
        "\n",
        "    with open(filename, 'rt') as f:\n",
        "        for line in f:\n",
        "            line = line.strip()\n",
        "            if len(line) == 0:\n",
        "                continue\n",
        "            else:\n",
        "                line = line.split()\n",
        "            instance_id = line[0]\n",
        "            label = float(line[1])\n",
        "            labels[instance_id] = label\n",
        "    return labels\n"
      ],
      "metadata": {
        "id": "rcchIvdkznBF"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Load Data"
      ],
      "metadata": {
        "id": "_iN_Vd3eSbkD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#test_data = load_data(\"/content/en_es/en_es.slam.20190204.test\")"
      ],
      "metadata": {
        "id": "INmoeFnSDBOP"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "training_data, training_labels = load_data(\"/content/en_es/en_es.slam.20190204.train\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pTIRglbADFqW",
        "outputId": "380f7d50-d314-4851-ee70-380a9997c1ad"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading instances...\n",
            "Loaded 317049 instances across 100000 exercises...\n",
            "Loaded 635368 instances across 200000 exercises...\n",
            "Loaded 951536 instances across 300000 exercises...\n",
            "Loaded 1271940 instances across 400000 exercises...\n",
            "Loaded 1591344 instances across 500000 exercises...\n",
            "Loaded 1911212 instances across 600000 exercises...\n",
            "Loaded 2227444 instances across 700000 exercises...\n",
            "Loaded 2546704 instances across 800000 exercises...\n",
            "Done loading 2622957 instances across 824012 exercises.\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "valid_data = load_data(\"/content/en_es/en_es.slam.20190204.dev\")\n",
        "valid_labels = load_labels(\"/content/en_es/en_es.slam.20190204.dev.key\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o56fqfEkzdQO",
        "outputId": "5636fd74-7d64-4178-b759-4c185160f679"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading instances...\n",
            "Loaded 334439 instances across 100000 exercises...\n",
            "Done loading 387374 instances across 115770 exercises.\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Pytorch Datasets"
      ],
      "metadata": {
        "id": "kBfmHACPSfuW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class ExcerciseDataset(torch.utils.data.Dataset):\n",
        "    def __init__(self, data, labels, sequence_size): \n",
        "        '''\n",
        "        Initializes the dataset.\n",
        "\n",
        "        INPUTS: What inputs do you need here?\n",
        "        '''\n",
        "        token_idx = 1\n",
        "        self.word2Idx = {\"unk\" : 0}\n",
        "        self.token_vocabulary = [\"unk\"]\n",
        "\n",
        "\n",
        "        pos_idx = 1\n",
        "        self.pos2Idx = {\"unk\" : 0}\n",
        "        self.pos_vocabulary = [\"unk\"]\n",
        "\n",
        "        morph_idx = 1\n",
        "        self.morph2Idx = {\"unk\" : 0}\n",
        "        self.morph_vocab = [\"unk\"]\n",
        "\n",
        "        dep_label_idx = 1\n",
        "        self.depLabel2Idx = {\"unk\": 0}\n",
        "        self.depLabelVocab = [\"unk\"]\n",
        "\n",
        "        self.user_keyed_data = {}\n",
        "        self.user_keyed_label = {}\n",
        "        \n",
        "        for i, instance in enumerate(data):\n",
        "          user = instance.user\n",
        "          if user not in self.user_keyed_data:\n",
        "            self.user_keyed_data[user] = []\n",
        "            self.user_keyed_label[user] = []\n",
        "          \n",
        "          exercise = []\n",
        "          \n",
        "          \n",
        "          token = instance.token.lower()\n",
        "          pos_tag = instance.part_of_speech.lower()\n",
        "          morphology = instance.morphological_features\n",
        "          dependency_label = instance.dependency_label.lower()\n",
        "          label = labels[instance.instance_id]\n",
        "\n",
        "          if token not in self.word2Idx:\n",
        "            self.word2Idx[token] = token_idx\n",
        "            self.token_vocabulary.append(token)\n",
        "            token_idx += 1\n",
        "\n",
        "          exercise.append(self.word2Idx[token])\n",
        "\n",
        "          if pos_tag not in self.pos2Idx:\n",
        "            self.pos2Idx[pos_tag] = pos_idx\n",
        "            self.pos_vocabulary.append(pos_tag)\n",
        "            pos_idx += 1\n",
        "\n",
        "          exercise.append(self.pos2Idx[pos_tag])\n",
        "\n",
        "          # morph_list = []\n",
        "          # for morph_feature in morphology:\n",
        "          #   if morph_feature not in self.morph2Idx:\n",
        "          #     self.morph2Idx[morph_feature] = morph_idx\n",
        "          #     self.morph_vocab.append(morph_feature)\n",
        "          #     morph_idx += 1\n",
        "          #   morph_list.append(self.morph2Idx[morph_feature])\n",
        "          \n",
        "          # exercise.append(morph_list)\n",
        "\n",
        "          if dependency_label not in self.depLabel2Idx:\n",
        "            self.depLabel2Idx[dependency_label] = dep_label_idx\n",
        "            self.depLabelVocab.append(dependency_label)\n",
        "            dep_label_idx += 1\n",
        "\n",
        "          exercise.append(self.depLabel2Idx[dependency_label])\n",
        "\n",
        "          self.user_keyed_data[user].append(torch.tensor(exercise, dtype = int))\n",
        "          self.user_keyed_label[user].append(label)\n",
        "          \n",
        "\n",
        "        #At this point we have the exercises for each user.\n",
        "\n",
        "        self.timesteped_data = []\n",
        "        self.timesteped_labels = []\n",
        "\n",
        "        #print(self.user_keyed_data[user])\n",
        "\n",
        "        for user in self.user_keyed_data:\n",
        "          #self.user_keyed_data[user] = torch.tensor(self.user_keyed_data[user])\n",
        "          for i in range(0, len(self.user_keyed_data[user]), 50):\n",
        "            chunk = self.user_keyed_data[user][i:i + sequence_size]\n",
        "            if(len(chunk) < 2):\n",
        "              continue;\n",
        "            self.timesteped_data.append(torch.stack(chunk,dim=0))\n",
        "            self.timesteped_labels.append(torch.FloatTensor(self.user_keyed_label[user][i:i + sequence_size]))\n",
        "        \n",
        "        self.length = len(self.timesteped_data)\n",
        "        \n",
        "    def __len__(self):\n",
        "        return self.length\n",
        "\n",
        "    def __getitem__(self, ind):\n",
        "        '''\n",
        "        TODO: RETURN THE MFCC COEFFICIENTS AND ITS CORRESPONDING LABELS\n",
        "\n",
        "        If you didn't do the loading and processing of the data in __init__,\n",
        "        do that here.\n",
        "\n",
        "        Once done, return a tuple of features and labels.\n",
        "        '''\n",
        "        data = self.timesteped_data[ind] # TODO\n",
        "        labels = self.timesteped_labels[ind] # TODO\n",
        "        return data, labels\n",
        "\n",
        "\n",
        "    def collate_fn(batch):\n",
        "        '''\n",
        "        TODO:\n",
        "        1.  Extract the features and labels from 'batch'\n",
        "        2.  We will additionally need to pad both features and labels,\n",
        "            look at pytorch's docs for pad_sequence\n",
        "        3.  This is a good place to perform transforms, if you so wish. \n",
        "            Performing them on batches will speed the process up a bit.\n",
        "        4.  Return batch of features, labels, lenghts of features, \n",
        "            and lengths of labels.\n",
        "        '''\n",
        "        # batch of input mfcc coefficients\n",
        "        batch_data_encoder = [x[0:len(x)//2] for x,y in batch] # TODO\n",
        "        batch_data_decoder = [x[len(x)//2:] for x,y in batch] # TODO\n",
        "        # batch of output phonemes\n",
        "        batch_labels_encoder = [y[0:len(y)//2] for x,y in batch] # TODO\n",
        "        batch_labels_decoder = [y[len(y)//2:] for x,y in batch] \n",
        "\n",
        "        # HINT: CHECK OUT -> pad_sequence (imported above)\n",
        "        # Also be sure to check the input format (batch_first)\n",
        "        batch_data_encoder_pad = pad_sequence(batch_data_encoder, batch_first=True, padding_value=0) # TODO\n",
        "        batch_data_decoder_pad = pad_sequence(batch_data_decoder, batch_first=True, padding_value=0)\n",
        "\n",
        "        encoder_lengths_data = [len(x) for x in batch_data_encoder] # TODO\n",
        "        decoder_lengths_data = [len(x) for x in batch_data_decoder] \n",
        "\n",
        "        batch_labels_encoder_pad = pad_sequence(batch_labels_encoder, batch_first=True, padding_value=0) # TODO\n",
        "        batch_labels_decoder_pad = pad_sequence(batch_labels_decoder, batch_first=True, padding_value=0)\n",
        "        encoder_lengths_labels =  [len(x) for x in batch_labels_encoder] # TODO\n",
        "        decoder_lengths_labels =  [len(x) for x in batch_labels_decoder] # TODO\n",
        "\n",
        "\n",
        "        # You may apply some transformation, Time and Frequency masking, here in the collate function;\n",
        "        # Food for thought -> Why are we applying the transformation here and not in the __getitem__?\n",
        "        #                  -> Would we apply transformation on the validation set as well?\n",
        "        #                  -> Is the order of axes / dimensions as expected for the transform functions?\n",
        "        \n",
        "        # Return the following values: padded features, padded labels, actual length of features, actual length of the labels\n",
        "        return batch_data_encoder_pad,batch_data_decoder_pad, batch_labels_encoder_pad,batch_labels_decoder_pad, torch.tensor(encoder_lengths_data), torch.tensor(decoder_lengths_data), torch.tensor(encoder_lengths_labels), torch.tensor(decoder_lengths_labels)"
      ],
      "metadata": {
        "id": "v3hHjz3MDKU0"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_data = ExcerciseDataset(training_data, training_labels, 256) #TODO\n",
        "train_loader = torch.utils.data.DataLoader(\n",
        "    dataset     = train_data, \n",
        "    num_workers = 8,\n",
        "    batch_size  = 64, \n",
        "    pin_memory  = True,\n",
        "    shuffle     = True,\n",
        "    collate_fn = ExcerciseDataset.collate_fn\n",
        ") #TODO"
      ],
      "metadata": {
        "id": "Hhv8oeQfSlVd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c43b18d3-b2f4-48d8-d861-ea058a353cc3"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.9/dist-packages/torch/utils/data/dataloader.py:561: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(_create_warning_msg(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "val_dataset = ExcerciseDataset(valid_data, valid_labels, 256) #TODO\n",
        "val_loader = torch.utils.data.DataLoader(\n",
        "    dataset     = val_dataset, \n",
        "    num_workers = 8,\n",
        "    batch_size  = 64, \n",
        "    pin_memory  = True,\n",
        "    shuffle     = True,\n",
        "    collate_fn = ExcerciseDataset.collate_fn\n",
        ") #TODO"
      ],
      "metadata": {
        "id": "YBA-bYamzxj0"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# sanity check\n",
        "i = 0;\n",
        "\n",
        "for data in val_loader:\n",
        "    x_encoder,x_decoder, y_encoder,y_decoder, lx_encoder,lx_decoder, ly_encoder, ly_decoder = data\n",
        "    print(x_encoder.shape,x_decoder.shape, y_encoder.shape,y_decoder.shape, lx_encoder.shape, lx_decoder.shape,ly_encoder.shape, ly_decoder.shape)\n",
        "    i += 1\n",
        "    if(i==2):\n",
        "      break "
      ],
      "metadata": {
        "id": "uk8Ef2mRT8Hh",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8017607e-a622-489f-c394-5f97cabfb1db"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([64, 128, 3]) torch.Size([64, 128, 3]) torch.Size([64, 128]) torch.Size([64, 128]) torch.Size([64]) torch.Size([64]) torch.Size([64]) torch.Size([64])\n",
            "torch.Size([64, 128, 3]) torch.Size([64, 128, 3]) torch.Size([64, 128]) torch.Size([64, 128]) torch.Size([64]) torch.Size([64]) torch.Size([64]) torch.Size([64])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Encoder"
      ],
      "metadata": {
        "id": "0f6KdPmUa3cW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Prepare GloVe for encoder\n",
        "matrix_len = len(train_data.token_vocabulary)\n",
        "weights_matrix = np.zeros((matrix_len, 50))\n",
        "words_found = 0\n",
        "\n",
        "for i, word in enumerate(train_data.token_vocabulary):\n",
        "    try: \n",
        "        weights_matrix[i] = word2vec[word]\n",
        "        words_found += 1\n",
        "    except KeyError:\n",
        "      if(i == 0):\n",
        "        print(\"here\")\n",
        "        weights_matrix[i] = np.zeros((50, ))\n",
        "      else:\n",
        "        weights_matrix[i] = np.random.normal(scale=0.6, size=(50, ))"
      ],
      "metadata": {
        "id": "auNs8M_OreWj"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(train_data.pos_vocabulary)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CE1o_D0lCYNt",
        "outputId": "910aa44e-9e61-4204-8e3f-8d310fa05c69"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "17"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class Encoder(torch.nn.Module):\n",
        "    '''\n",
        "    The Encoder takes utterances as inputs and returns latent feature representations\n",
        "    '''\n",
        "    def __init__(self, token_embedding_weight_matrix, encoder_hidden_size):\n",
        "        super(Encoder, self).__init__()\n",
        "\n",
        "        self.token_embedding = torch.nn.Embedding(len(train_data.token_vocabulary), 50)\n",
        "        self.token_embedding.load_state_dict({'weight': torch.as_tensor(token_embedding_weight_matrix)})\n",
        "        self.token_embedding.weight.requires_grad = False\n",
        "\n",
        "        self.pos_embedding = torch.nn.Embedding(len(train_data.pos_vocabulary), 10)\n",
        "        self.dependency_embedding = torch.nn.Embedding(len(train_data.depLabelVocab), 10)\n",
        "\n",
        "        self.lstm1 = torch.nn.LSTM(input_size = 71, hidden_size = encoder_hidden_size, num_layers = 3, bidirectional = True, batch_first = True, dropout = 0.3)\n",
        "\n",
        "    def forward(self, x, x_lens, labels):\n",
        "        # Where are x and x_lens coming from? The dataloader\n",
        "        #TODO: Call the embedding layer\n",
        "        token_embeddings = self.token_embedding(x[:,:,0])\n",
        "        pos_embeddings = self.pos_embedding(x[:,:,1])\n",
        "        dependency_embeddings = self.dependency_embedding(x[:,:,2])\n",
        "\n",
        "        concatenated_out = torch.cat((token_embeddings,pos_embeddings,dependency_embeddings, labels.reshape(labels.shape[0], labels.shape[1], 1)), dim=2)\n",
        "\n",
        "        #print(concatenated_out.shape)\n",
        "        # TODO: Pack Padded Sequence\n",
        "        packed_out = pack_padded_sequence(concatenated_out, x_lens, batch_first = True, enforce_sorted=False)\n",
        "        # TODO: Pass Sequence through the pyramidal Bi-LSTM layer\n",
        "        out = self.lstm1(packed_out)[0]\n",
        "        #out = self.pBLSTMs(out)\n",
        "        # TODO: Pad Packed Sequence\n",
        "        encoder_outputs, encoder_lens = pad_packed_sequence(out, batch_first = True)\n",
        "        \n",
        "        # Remember the number of output(s) each function returns\n",
        "\n",
        "        return encoder_outputs, encoder_lens"
      ],
      "metadata": {
        "id": "Eyg8grmfa4Nz"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# encoder = Encoder(weights_matrix, 16)"
      ],
      "metadata": {
        "id": "FCT3SO9zv5y8"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# for i, data in enumerate(train_loader):\n",
        "#   x_encoder,x_decoder, y_encoder,y_decoder, lx_encoder,lx_decoder, ly_encoder, ly_decoder = data\n",
        "#   encoder_outputs, encoder_lens = encoder(x_encoder, lx_encoder, y_encoder)\n",
        "#   # encoder_out_new = torch.zeros((encoder_outputs.shape[0], encoder_outputs.shape[2]))\n",
        "#   # for batch_output_index in range(encoder_outputs.shape[0]):\n",
        "#   #   encoder_out_new[batch_output_index] = torch.sum(encoder_outputs[batch_output_index,0:encoder_lens[batch_output_index]], dim = 0)\n",
        "#   # print(encoder_out_new.shape)\n",
        "#   #print(torch.sum(encoder_outputs[:,:encoder_lens], dim = 1).shape)"
      ],
      "metadata": {
        "id": "VcIDPxQswThA"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Decoder"
      ],
      "metadata": {
        "id": "qfqfTmfuyX6q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class PermuteBlock(torch.nn.Module):\n",
        "    def forward(self, x):\n",
        "        return x.transpose(1, 2)"
      ],
      "metadata": {
        "id": "BFGjV5ElSdPs"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Decoder(torch.nn.Module):\n",
        "\n",
        "    def __init__(self,token_embedding_weight_matrix, decoder_hidden_size, output_size = 1):\n",
        "        super().__init__()\n",
        "\n",
        "        self.token_embedding = torch.nn.Embedding(len(train_data.token_vocabulary), 50)\n",
        "        self.token_embedding.load_state_dict({'weight': torch.as_tensor(token_embedding_weight_matrix)})\n",
        "        self.token_embedding.weight.requires_grad = False\n",
        "\n",
        "        self.pos_embedding = torch.nn.Embedding(len(train_data.pos_vocabulary), 10)\n",
        "        self.dependency_embedding = torch.nn.Embedding(len(train_data.depLabelVocab), 10)\n",
        "\n",
        "        self.lstm1 = torch.nn.GRU(input_size = 70, hidden_size = decoder_hidden_size, num_layers = 1, bidirectional = False, batch_first = True, dropout = 0.3)\n",
        "\n",
        "        self.mlp = torch.nn.Sequential(\n",
        "            PermuteBlock(), \n",
        "            torch.nn.BatchNorm1d(decoder_hidden_size), \n",
        "            PermuteBlock(),\n",
        "            torch.nn.Linear(decoder_hidden_size, decoder_hidden_size//2),\n",
        "            PermuteBlock(), \n",
        "            torch.nn.BatchNorm1d(decoder_hidden_size//2), \n",
        "            PermuteBlock(),\n",
        "            torch.nn.GELU(),\n",
        "            torch.nn.Dropout(p = 0.2),\n",
        "            torch.nn.Linear(decoder_hidden_size//2, output_size),\n",
        "        )\n",
        "        \n",
        "        #self.sigmoid = torch.nn.Sigmoid(dim=2)\n",
        "\n",
        "    def forward(self, encoder_out, x, x_lens):\n",
        "        #TODO call your MLP\n",
        "        #TODO Think what should be the final output of the decoder for the classification \n",
        "\n",
        "        #Assuming encoder_out is of size BatchSize, H_out\n",
        "        token_embeddings = self.token_embedding(x[:,:,0])\n",
        "        pos_embeddings = self.pos_embedding(x[:,:,1])\n",
        "        dependency_embeddings = self.dependency_embedding(x[:,:,2])\n",
        "\n",
        "        concatenated_out = torch.cat((token_embeddings,pos_embeddings,dependency_embeddings), dim=2)\n",
        "\n",
        "        packed_out = pack_padded_sequence(concatenated_out, x_lens, batch_first = True, enforce_sorted=False)\n",
        "        out = self.lstm1(packed_out, encoder_out.reshape(1,encoder_out.shape[0], encoder_out.shape[1]))[0]\n",
        "        decoder_output, decoder_lens = pad_packed_sequence(out, batch_first = True)\n",
        "\n",
        "        out = self.mlp(decoder_output)\n",
        "        return out.reshape(out.shape[0],out.shape[1])"
      ],
      "metadata": {
        "id": "KZaLH8b2yaNd"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# decoder = Decoder(weights_matrix, 32, 1)"
      ],
      "metadata": {
        "id": "nGEZtrWrb8DZ"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# for i, data in enumerate(train_loader):\n",
        "#   x_encoder,x_decoder,y_encoder,y_decoder,lx_encoder,lx_decoder, ly_encoder, ly_decoder = data\n",
        "\n",
        "#   #print(encoder(x_encoder, lx_encoder, y_encoder)[0].shape)\n",
        "#   encoder_out, encoder_lens = encoder(x_encoder, lx_encoder, y_encoder)\n",
        "\n",
        "#   encoder_out_new = torch.zeros((encoder_out.shape[0], encoder_out.shape[2]))\n",
        "\n",
        "#   for batch_output_index in range(encoder_out.shape[0]):\n",
        "#     encoder_out_new[batch_output_index] = torch.sum(encoder_out[batch_output_index,0:encoder_lens[batch_output_index]], dim = 0)\n",
        "\n",
        "#   decoder_out  = decoder(encoder_out_new, x_decoder, lx_decoder)\n",
        "#   print(decoder_out.shape)"
      ],
      "metadata": {
        "id": "bte7OsxDUR_8"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Complete Model"
      ],
      "metadata": {
        "id": "_XyYTj7JWUab"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class KnowledgeModel(torch.nn.Module):\n",
        "\n",
        "    def __init__(self, embed_size=128, output_size=1):\n",
        "        super().__init__()\n",
        "\n",
        "        #Prepare GloVe for encoder\n",
        "        matrix_len = len(train_data.token_vocabulary)\n",
        "        weights_matrix = np.zeros((matrix_len, 50))\n",
        "        words_found = 0\n",
        "\n",
        "        for i, word in enumerate(train_data.token_vocabulary):\n",
        "          try: \n",
        "              weights_matrix[i] = word2vec[word]\n",
        "              words_found += 1\n",
        "          except KeyError:\n",
        "            if(i == 0):\n",
        "              weights_matrix[i] = np.zeros((50, ))\n",
        "            else:\n",
        "              weights_matrix[i] = np.random.normal(scale=0.6, size=(50, ))\n",
        "\n",
        "        self.encoder        = Encoder(weights_matrix, embed_size) # TODO: Initialize Encoder\n",
        "        self.decoder        = Decoder(weights_matrix, 2*embed_size, output_size) # TODO: Initialize Decoder \n",
        "    \n",
        "    def forward(self, x_encoder,x_encoder_lengths, y_encoder_labels, x_decoder, x_decoder_lengths):\n",
        "        encoder_out, encoder_lens = self.encoder(x_encoder, x_encoder_lengths, y_encoder_labels)\n",
        "        encoder_out_new = torch.zeros((encoder_out.shape[0], encoder_out.shape[2]))\n",
        "        for batch_output_index in range(encoder_out.shape[0]):\n",
        "          encoder_out_new[batch_output_index] = torch.sum(encoder_out[batch_output_index,0:encoder_lens[batch_output_index]], dim = 0)\n",
        "        #print(encoder_out_new.shape)\n",
        "        encoder_out_new = encoder_out_new.to(device)\n",
        "        decoder_out  = self.decoder(encoder_out_new, x_decoder,  x_decoder_lengths)\n",
        "\n",
        "        return decoder_out"
      ],
      "metadata": {
        "id": "TmFYQO04WVl6"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = KnowledgeModel(\n",
        "    embed_size  = 512,\n",
        "    output_size = 1\n",
        ").to(device)\n",
        "print(model)\n",
        "summary(model,x_encoder.to(device),lx_encoder,y_encoder.to(device), x_decoder.to(device),lx_decoder)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 796
        },
        "id": "Dg14_QLUrEyD",
        "outputId": "2dc1eed4-6c39-4dad-d561-bb2d09d8e7df"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.9/dist-packages/torch/nn/modules/rnn.py:71: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.3 and num_layers=1\n",
            "  warnings.warn(\"dropout option adds dropout after all but last \"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "KnowledgeModel(\n",
            "  (encoder): Encoder(\n",
            "    (token_embedding): Embedding(1968, 50)\n",
            "    (pos_embedding): Embedding(17, 10)\n",
            "    (dependency_embedding): Embedding(42, 10)\n",
            "    (lstm1): LSTM(71, 512, num_layers=3, batch_first=True, dropout=0.3, bidirectional=True)\n",
            "  )\n",
            "  (decoder): Decoder(\n",
            "    (token_embedding): Embedding(1968, 50)\n",
            "    (pos_embedding): Embedding(17, 10)\n",
            "    (dependency_embedding): Embedding(42, 10)\n",
            "    (lstm1): GRU(70, 1024, batch_first=True, dropout=0.3)\n",
            "    (mlp): Sequential(\n",
            "      (0): PermuteBlock()\n",
            "      (1): BatchNorm1d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (2): PermuteBlock()\n",
            "      (3): Linear(in_features=1024, out_features=512, bias=True)\n",
            "      (4): PermuteBlock()\n",
            "      (5): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (6): PermuteBlock()\n",
            "      (7): GELU(approximate='none')\n",
            "      (8): Dropout(p=0.2, inplace=False)\n",
            "      (9): Linear(in_features=512, out_features=1, bias=True)\n",
            "    )\n",
            "  )\n",
            ")\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-26-99655bacf7de>\u001b[0m in \u001b[0;36m<cell line: 6>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m ).to(device)\n\u001b[1;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0msummary\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mx_encoder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mlx_encoder\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my_encoder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx_decoder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mlx_decoder\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'summary' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Training**"
      ],
      "metadata": {
        "id": "7gpYY89-tnbE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\n",
        "scheduler =  torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, factor=0.5, patience=3, mode='min') # fill this out\n",
        "criterion = torch.nn.BCEWithLogitsLoss(reduction = 'none', pos_weight = torch.tensor([10]).to(device))\n",
        "# Mixed Precision, if you need it\n",
        "scaler = torch.cuda.amp.GradScaler()"
      ],
      "metadata": {
        "id": "A_1RvCjDuy03"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def create_loss_mask(lens):\n",
        "    mask = torch.arange(max(lens))\n",
        "    mask = torch.tile(mask, (len(lens), 1))\n",
        "    t = torch.tile( lens.reshape((len(lens), 1)) , (1, mask.shape[1]))\n",
        "    mask = mask < t\n",
        "    return mask"
      ],
      "metadata": {
        "id": "Z0U2fr43tpRx"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tqdm import tqdm\n",
        "\n",
        "def train_model(model, train_loader, criterion, optimizer):\n",
        "    \n",
        "    model.train()\n",
        "    batch_bar = tqdm(total=len(train_loader), dynamic_ncols=True, leave=False, position=0, desc='Train') \n",
        "\n",
        "    total_loss = 0\n",
        "\n",
        "    for i, data in enumerate(train_loader):\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        x_encoder,x_decoder,y_encoder,y_decoder,lx_encoder,lx_decoder, ly_encoder, ly_decoder = data\n",
        "        x_encoder,x_decoder,y_encoder,y_decoder = x_encoder.to(device),x_decoder.to(device),y_encoder.to(device),y_decoder.to(device)\n",
        "        #x, y = x.to(device), y.to(device)\n",
        "\n",
        "        with torch.cuda.amp.autocast():     \n",
        "            decoder_out = model(x_encoder,lx_encoder,y_encoder,x_decoder,lx_decoder)\n",
        "            #print(h.shape)\n",
        "            #print(lh)\n",
        "            loss = criterion(decoder_out, y_decoder)\n",
        "            loss_mask = create_loss_mask(ly_decoder)\n",
        "            loss_mask = loss_mask.to(device)\n",
        "            masked_loss = loss * loss_mask\n",
        "\n",
        "            loss = torch.sum(masked_loss)/torch.sum(loss_mask)\n",
        "\n",
        "\n",
        "        total_loss += loss.item()\n",
        "\n",
        "        batch_bar.set_postfix(\n",
        "            loss=\"{:.04f}\".format(float(total_loss / (i + 1))),\n",
        "            lr=\"{:.06f}\".format(float(optimizer.param_groups[0]['lr'])))\n",
        "\n",
        "        batch_bar.update() # Update tqdm bar\n",
        "\n",
        "        # Another couple things you need for FP16. \n",
        "        scaler.scale(loss).backward() # This is a replacement for loss.backward()\n",
        "        scaler.step(optimizer) # This is a replacement for optimizer.step()\n",
        "        scaler.update() # This is something added just for FP16\n",
        "\n",
        "        del x_encoder,x_decoder,y_encoder,y_decoder,lx_encoder,lx_decoder, ly_encoder, ly_decoder, decoder_out, loss \n",
        "        torch.cuda.empty_cache()\n",
        "\n",
        "    batch_bar.close() # You need this to close the tqdm bar\n",
        "    \n",
        "    return total_loss / len(train_loader)\n",
        "\n",
        "\n",
        "def validate_model(model, val_loader):\n",
        "\n",
        "    model.eval()\n",
        "    batch_bar = tqdm(total=len(val_loader), dynamic_ncols=True, position=0, leave=False, desc='Val')\n",
        "\n",
        "    total_loss = 0\n",
        "    vdist = 0\n",
        "\n",
        "    for i, data in enumerate(val_loader):\n",
        "\n",
        "        x_encoder,x_decoder,y_encoder,y_decoder,lx_encoder,lx_decoder, ly_encoder, ly_decoder = data\n",
        "        x_encoder,x_decoder,y_encoder,y_decoder = x_encoder.to(device),x_decoder.to(device),y_encoder.to(device),y_decoder.to(device)\n",
        "\n",
        "        #x, y = x.to(device), y.to(device)\n",
        "\n",
        "        with torch.cuda.amp.autocast():   \n",
        "          with torch.inference_mode():\n",
        "              decoder_out = model(x_encoder,lx_encoder,y_encoder,x_decoder,lx_decoder)\n",
        "              #h = torch.permute(h, (1, 0, 2))\n",
        "              loss = criterion(decoder_out, y_decoder)\n",
        "              loss_mask = create_loss_mask(ly_decoder)\n",
        "              loss_mask = loss_mask.to(device)\n",
        "              masked_loss = loss * loss_mask\n",
        "\n",
        "              loss = torch.sum(masked_loss)/torch.sum(loss_mask)\n",
        "\n",
        "        total_loss += float(loss.item())\n",
        "\n",
        "        batch_bar.set_postfix(loss=\"{:.04f}\".format(float(total_loss / (i + 1))), dist=\"{:.04f}\".format(float(vdist / (i + 1))))\n",
        "\n",
        "        batch_bar.update()\n",
        "    \n",
        "        del x_encoder,x_decoder,y_encoder,y_decoder,lx_encoder,lx_decoder, ly_encoder, ly_decoder,decoder_out, loss\n",
        "        torch.cuda.empty_cache()\n",
        "        \n",
        "    batch_bar.close()\n",
        "    total_loss = total_loss/len(val_loader)\n",
        "    return total_loss"
      ],
      "metadata": {
        "id": "1rZhYg8-usp1"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "del word2vec"
      ],
      "metadata": {
        "id": "Hv9wCuJnTDGR"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "torch.cuda.empty_cache()\n",
        "gc.collect()\n",
        "\n",
        "for epoch in range(0, 50):\n",
        "\n",
        "    print(\"\\nEpoch: {}/{}\".format(epoch+1, 50))\n",
        "    \n",
        "    curr_lr = optimizer.param_groups[0]['lr']\n",
        "\n",
        "    train_loss              = train_model(model, train_loader, criterion, optimizer) \n",
        "    valid_loss  = validate_model(model, val_loader)\n",
        "    scheduler.step(valid_loss)\n",
        "\n",
        "    print(\"\\tTrain Loss {:.04f}\\t Learning Rate {:.07f}\".format(train_loss, curr_lr))\n",
        "    print(\"Val Loss {:.04f}\".format(valid_loss))\n",
        "\n",
        "\n",
        "    # wandb.log({\n",
        "    #     'train_loss': train_loss,  \n",
        "    #     'valid_dist': valid_dist, \n",
        "    #     'valid_loss': valid_loss, \n",
        "    #     'lr'        : curr_lr\n",
        "    # })\n",
        "    \n",
        "#     save_model(model, optimizer, scheduler, ['valid_dist', valid_dist], epoch, epoch_model_path)\n",
        "#     wandb.save(epoch_model_path)\n",
        "#     print(\"Saved epoch model\")\n",
        "\n",
        "#     if valid_dist <= best_lev_dist:\n",
        "#         best_lev_dist = valid_dist\n",
        "#         save_model(model, optimizer, scheduler, ['valid_dist', valid_dist], epoch, best_model_path)\n",
        "#         wandb.save(best_model_path)\n",
        "#         print(\"Saved best model\")\n",
        "#       # You may find it interesting to exlplore Wandb Artifcats to version your models\n",
        "# run.finish()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HXoIrQCIwIp_",
        "outputId": "6c1df79b-ae24-4798-844f-ca77daa3a408"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch: 1/50\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTrain:   0%|          | 0/839 [00:00<?, ?it/s]/usr/local/lib/python3.9/dist-packages/torch/utils/data/dataloader.py:561: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(_create_warning_msg(\n",
            "Train:  73%|███████▎  | 611/839 [07:45<51:17, 13.50s/it, loss=1.3144, lr=0.001000]"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Extra\n"
      ],
      "metadata": {
        "id": "YhroSFe6IUYV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# class ExcerciseToken(object):\n",
        "#   def __init__(self, token, id, pos_tag, morphological_features, dep_label, dep_edge_head):\n",
        "#     self.token = token\n",
        "#     self.id = id\n",
        "#     self.pos_tag = pos_tag\n",
        "#     self.morphological_features = morphological_features\n",
        "#     self.dep_label = dep_label\n",
        "#     self.dep_edge_head = dep_edge_head\n",
        "  \n",
        "#   def set_label(self, label):\n",
        "#     self.label = label\n"
      ],
      "metadata": {
        "id": "Sz4qwkzDIT2u"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# class ExcerciseInformation(object):\n",
        "#   def __init__(self):\n",
        "#     self.exercise_tokens = []\n",
        "#     self.prompt = \"\"\n",
        "#     self.user = \"\"\n",
        "#     self.countries = \"\"\n",
        "#     self.days = 0.0\n",
        "#     self.client = \"\"\n",
        "#     self.session = \"\"\n",
        "#     self.format = \"\"\n",
        "#     self.time = 0.0\n",
        "  \n",
        "#   def add_exercise_token(self, excercise_token_info: ExcerciseToken):\n",
        "#     self.exercise_tokens.append(excercise_token_info)\n",
        "  \n",
        "#   def set_prompt(self, prompt: str):\n",
        "#     self.prompt = prompt\n",
        "\n",
        "#   def set_user(self, user: str):\n",
        "#     self.user = user\n",
        "  \n",
        "#   def set_countries(self, countries: str):\n",
        "#     self.countries = countries\n",
        "\n",
        "#   def set_days(self, days: float):\n",
        "#     self.days = days\n",
        "  \n",
        "#   def set_client(self, client: str):\n",
        "#     self.client = client\n",
        "  \n",
        "#   def set_session(self, session: str):\n",
        "#     self.session = session\n",
        "  \n",
        "#   def set_format(self, format: str):\n",
        "#     self.format = format\n",
        "\n",
        "#   def set_time(self, time: float):\n",
        "#     self.time = time\n",
        "  \n",
        "\n"
      ],
      "metadata": {
        "id": "Gxqn_2VPIV_-"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}