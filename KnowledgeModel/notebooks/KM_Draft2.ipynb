{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "gpuClass": "standard",
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import random, string, urllib.request, json, getpass\n",
        "\n",
        "#Generate root password\n",
        "password = ''.join(random.choice(string.ascii_letters + string.digits) for i in range(20))\n",
        "\n",
        "#Download ngrok\n",
        "! wget -q -c -nc https://bin.equinox.io/c/4VmDzA7iaHb/ngrok-stable-linux-amd64.zip\n",
        "! unzip -qq -n ngrok-stable-linux-amd64.zip\n",
        "\n",
        "#Setup sshd\n",
        "! apt-get install -qq -o=Dpkg::Use-Pty=0 openssh-server pwgen > /dev/null\n",
        "\n",
        "#Set root password\n",
        "! echo root:$password | chpasswd\n",
        "! mkdir -p /var/run/sshd\n",
        "! echo \"PermitRootLogin yes\" >> /etc/ssh/sshd_config\n",
        "! echo \"PasswordAuthentication yes\" >> /etc/ssh/sshd_config\n",
        "! echo \"LD_LIBRARY_PATH=/usr/lib64-nvidia\" >> /root/.bashrc\n",
        "! echo \"export LD_LIBRARY_PATH\" >> /root/.bashrc\n",
        "\n",
        "#Run sshd\n",
        "get_ipython().system_raw('/usr/sbin/sshd -D &')\n",
        "\n",
        "#Ask token\n",
        "print(\"Copy authtoken from https://dashboard.ngrok.com/auth\")\n",
        "authtoken = getpass.getpass()\n",
        "\n",
        "#Create tunnel\n",
        "get_ipython().system_raw('./ngrok authtoken $authtoken && ./ngrok tcp 22 &')\n",
        "\n",
        "#Get public address and print connect command\n",
        "with urllib.request.urlopen('http://localhost:4040/api/tunnels') as response:\n",
        "  data = json.loads(response.read().decode())\n",
        "  (host, port) = data['tunnels'][0]['public_url'][6:].split(':')\n",
        "  print(f'SSH command: ssh -p{port} root@{host}')\n",
        "\n",
        "#Print root password\n",
        "print(f'Root password: {password}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-0FSvxKOruQv",
        "outputId": "627b30b7-2b0f-485a-d51f-92c21fa758de"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Copy authtoken from https://dashboard.ngrok.com/auth\n",
            "··········\n",
            "SSH command: ssh -p15633 root@6.tcp.ngrok.io\n",
            "Root password: JsnWCAfPP9SBwiT5qw0A\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "6999mXBSEoHl"
      },
      "outputs": [],
      "source": [
        "import argparse\n",
        "from collections import defaultdict, namedtuple\n",
        "from io import open\n",
        "import math\n",
        "import os\n",
        "from random import shuffle, uniform\n",
        "from datetime import datetime\n",
        "from future.utils import iterkeys, iteritems\n",
        "import torch\n",
        "\n",
        "from future.builtins import range\n",
        "from future.utils import iteritems\n",
        "import pickle\n",
        "import numpy as np\n",
        "from torch.nn.utils.rnn import pad_sequence, pack_padded_sequence, pad_packed_sequence"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# !pip install scipy\n",
        "# !pip install matplotlib\n",
        "# !pip install sklearn\n",
        "!pip install torchsummaryX -q\n",
        "from torchsummaryX import summary"
      ],
      "metadata": {
        "id": "kQUs_FYrHQEO"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import gc"
      ],
      "metadata": {
        "id": "sOY6ysWQ1EwA"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'"
      ],
      "metadata": {
        "id": "VmO3lJnO23IR"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Get Glove Vectors\n",
        "!wget https://nlp.stanford.edu/data/glove.6B.zip\n",
        "!unzip /content/glove.6B.zip"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t6PvbACjSGzA",
        "outputId": "6e521365-16ec-451d-ff78-0d6939e65aa2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2023-04-07 22:32:04--  https://nlp.stanford.edu/data/glove.6B.zip\n",
            "Resolving nlp.stanford.edu (nlp.stanford.edu)... 171.64.67.140\n",
            "Connecting to nlp.stanford.edu (nlp.stanford.edu)|171.64.67.140|:443... connected.\n",
            "HTTP request sent, awaiting response... 301 Moved Permanently\n",
            "Location: https://downloads.cs.stanford.edu/nlp/data/glove.6B.zip [following]\n",
            "--2023-04-07 22:32:05--  https://downloads.cs.stanford.edu/nlp/data/glove.6B.zip\n",
            "Resolving downloads.cs.stanford.edu (downloads.cs.stanford.edu)... 171.64.64.22\n",
            "Connecting to downloads.cs.stanford.edu (downloads.cs.stanford.edu)|171.64.64.22|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 862182613 (822M) [application/zip]\n",
            "Saving to: ‘glove.6B.zip.1’\n",
            "\n",
            "glove.6B.zip.1        3%[                    ]  29.30M  8.92MB/s    eta 86s    ^C\n",
            "Archive:  /content/glove.6B.zip\n",
            "replace glove.6B.50d.txt? [y]es, [n]o, [A]ll, [N]one, [r]ename: n\n",
            "replace glove.6B.100d.txt? [y]es, [n]o, [A]ll, [N]one, [r]ename: n\n",
            "replace glove.6B.200d.txt? [y]es, [n]o, [A]ll, [N]one, [r]ename: n\n",
            "replace glove.6B.300d.txt? [y]es, [n]o, [A]ll, [N]one, [r]ename: n\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Prepare Glove Vectors\n",
        "word2vec = {}\n",
        "with open(\"/content/glove.6B.50d.txt\", 'r', encoding=\"utf-8\") as f:\n",
        "    for l in f:\n",
        "        line = l.split()\n",
        "        word = line[0]\n",
        "        vect = np.array(line[1:]).astype(float)\n",
        "        word2vec[word] = vect\n",
        "pickle.dump(word2vec, open(f'/content/6B.50_word2Vec.pkl', 'wb'))"
      ],
      "metadata": {
        "id": "O5UWvnXoSJFH"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Data Loading Utilities"
      ],
      "metadata": {
        "id": "XV93xsMXSVzt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class InstanceData(object):\n",
        "    \"\"\"\n",
        "    A bare-bones class to store the included properties of each instance. This is meant to act as easy access to the\n",
        "    data, and provides a launching point for deriving your own features from the data.\n",
        "    \"\"\"\n",
        "    def __init__(self, instance_properties):\n",
        "\n",
        "        # Parameters specific to this instance\n",
        "        self.instance_id = instance_properties['instance_id']\n",
        "        self.token = instance_properties['token']\n",
        "        self.part_of_speech = instance_properties['part_of_speech']\n",
        "        self.morphological_features = instance_properties['morphological_features']\n",
        "        self.dependency_label = instance_properties['dependency_label']\n",
        "        self.dependency_edge_head = instance_properties['dependency_edge_head']\n",
        "\n",
        "        # Derived parameters specific to this instance\n",
        "        self.exercise_index = int(self.instance_id[8:10])\n",
        "        self.token_index = int(self.instance_id[10:12])\n",
        "\n",
        "        # Derived parameters specific to this exercise\n",
        "        self.exercise_id = self.instance_id[:10]\n",
        "\n",
        "        # Parameters shared across the whole session\n",
        "        self.user = instance_properties['user']\n",
        "        self.countries = instance_properties['countries']\n",
        "        self.days = instance_properties['days']\n",
        "        self.client = instance_properties['client']\n",
        "        self.session = instance_properties['session']\n",
        "        self.format = instance_properties['format']\n",
        "        self.time = instance_properties['time']\n",
        "        self.prompt = instance_properties.get('prompt', None)\n",
        "\n",
        "        # Derived parameters shared across the whole session\n",
        "        self.session_id = self.instance_id[:8]\n",
        "\n",
        "    def to_features(self):\n",
        "        \"\"\"\n",
        "        Prepares those features that we wish to use in the LogisticRegression example in this file. We introduce a bias,\n",
        "        and take a few included features to use. Note that this dict restructures the corresponding features of the\n",
        "        input dictionary, 'instance_properties'.\n",
        "\n",
        "        Returns:\n",
        "            to_return: a representation of the features we'll use for logistic regression in a dict. A key/feature is a\n",
        "                key/value pair of the original 'instance_properties' dict, and we encode this feature as 1.0 for 'hot'.\n",
        "        \"\"\"\n",
        "        to_return = dict()\n",
        "\n",
        "        to_return['bias'] = 1.0\n",
        "        to_return['user:' + self.user] = 1.0\n",
        "        to_return['format:' + self.format] = 1.0\n",
        "        to_return['token:' + self.token.lower()] = 1.0\n",
        "\n",
        "        to_return['part_of_speech:' + self.part_of_speech] = 1.0\n",
        "        for morphological_feature in self.morphological_features:\n",
        "            to_return['morphological_feature:' + morphological_feature] = 1.0\n",
        "        to_return['dependency_label:' + self.dependency_label] = 1.0\n",
        "        \n",
        "        time = datetime.now()\n",
        "        if(time.second %10 == 0 and time.microsecond == 0):\n",
        "          print(time)\n",
        "          \n",
        "        return to_return"
      ],
      "metadata": {
        "id": "r1dTGVEBSU6a"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Load data from the file\n",
        "def load_data(filename):\n",
        "    \"\"\"\n",
        "    This method loads and returns the data in filename. If the data is labelled training data, it returns labels too.\n",
        "\n",
        "    Parameters:\n",
        "        filename: the location of the training or test data you want to load.\n",
        "\n",
        "    Returns:\n",
        "        data: a list of InstanceData objects from that data type and track.\n",
        "        labels (optional): if you specified training data, a dict of instance_id:label pairs.\n",
        "    \"\"\"\n",
        "\n",
        "    # 'data' stores a list of 'InstanceData's as values.\n",
        "    data = []\n",
        "\n",
        "    # If this is training data, then 'labels' is a dict that contains instance_ids as keys and labels as values.\n",
        "    training = False\n",
        "    if filename.find('train') != -1:\n",
        "        training = True\n",
        "\n",
        "    if training:\n",
        "        labels = dict()\n",
        "\n",
        "    num_exercises = 0\n",
        "    print('Loading instances...')\n",
        "    instance_properties = dict()\n",
        "\n",
        "    with open(filename, 'rt') as f:\n",
        "        for line in f:\n",
        "            line = line.strip()\n",
        "\n",
        "            # If there's nothing in the line, then we're done with the exercise. Print if needed, otherwise continue\n",
        "            if len(line) == 0:\n",
        "                num_exercises += 1\n",
        "                if num_exercises % 100000 == 0:\n",
        "                    print('Loaded ' + str(len(data)) + ' instances across ' + str(num_exercises) + ' exercises...')\n",
        "                instance_properties = dict()\n",
        "\n",
        "            # If the line starts with #, then we're beginning a new exercise\n",
        "            elif line[0] == '#':\n",
        "                if 'prompt' in line:\n",
        "                    instance_properties['prompt'] = line.split(':')[1]\n",
        "                else:\n",
        "                    list_of_exercise_parameters = line[2:].split()\n",
        "                    for exercise_parameter in list_of_exercise_parameters:\n",
        "                        [key, value] = exercise_parameter.split(':')\n",
        "                        if key == 'countries':\n",
        "                            value = value.split('|')\n",
        "                        elif key == 'days':\n",
        "                            value = float(value)\n",
        "                        elif key == 'time':\n",
        "                            if value == 'null':\n",
        "                                value = None\n",
        "                            else:\n",
        "                                assert '.' not in value\n",
        "                                value = int(value)\n",
        "                        instance_properties[key] = value\n",
        "\n",
        "            # Otherwise we're parsing a new Instance for the current exercise\n",
        "            else:\n",
        "                line = line.split()\n",
        "                if training:\n",
        "                    assert len(line) == 7\n",
        "                else:\n",
        "                    assert len(line) == 6\n",
        "                assert len(line[0]) == 12\n",
        "\n",
        "                instance_properties['instance_id'] = line[0]\n",
        "\n",
        "                instance_properties['token'] = line[1]\n",
        "                instance_properties['part_of_speech'] = line[2]\n",
        "\n",
        "                instance_properties['morphological_features'] = dict()\n",
        "                for l in line[3].split('|'):\n",
        "                    [key, value] = l.split('=')\n",
        "                    if key == 'Person':\n",
        "                        value = int(value)\n",
        "                    instance_properties['morphological_features'][key] = value\n",
        "\n",
        "                instance_properties['dependency_label'] = line[4]\n",
        "                instance_properties['dependency_edge_head'] = int(line[5])\n",
        "                if training:\n",
        "                    label = float(line[6])\n",
        "                    labels[instance_properties['instance_id']] = label\n",
        "                data.append(InstanceData(instance_properties=instance_properties))\n",
        "\n",
        "        print('Done loading ' + str(len(data)) + ' instances across ' + str(num_exercises) +\n",
        "              ' exercises.\\n')\n",
        "\n",
        "    if training:\n",
        "        return data, labels\n",
        "    else:\n",
        "        return data"
      ],
      "metadata": {
        "id": "ZYZ_49knNvCh"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def load_labels(filename):\n",
        "    \"\"\"\n",
        "    This loads labels, either the actual ones or your predictions.\n",
        "\n",
        "    Parameters:\n",
        "        filename: the filename pointing to your labels\n",
        "\n",
        "    Returns:\n",
        "        labels: a dict of instance_ids as keys and labels between 0 and 1 as values\n",
        "    \"\"\"\n",
        "    labels = dict()\n",
        "\n",
        "    with open(filename, 'rt') as f:\n",
        "        for line in f:\n",
        "            line = line.strip()\n",
        "            if len(line) == 0:\n",
        "                continue\n",
        "            else:\n",
        "                line = line.split()\n",
        "            instance_id = line[0]\n",
        "            label = float(line[1])\n",
        "            labels[instance_id] = label\n",
        "    return labels\n"
      ],
      "metadata": {
        "id": "rcchIvdkznBF"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def compute_acc(actual, predicted):\n",
        "    \"\"\"\n",
        "    Computes the accuracy of your predictions, using 0.5 as a cutoff.\n",
        "\n",
        "    Note that these inputs are lists, not dicts; they assume that actual and predicted are in the same order.\n",
        "\n",
        "    Parameters (here and below):\n",
        "        actual: a list of the actual labels\n",
        "        predicted: a list of your predicted labels\n",
        "    \"\"\"\n",
        "    num = len(actual)\n",
        "    acc = 0.\n",
        "    for i in range(num):\n",
        "        if round(actual[i], 0) == round(predicted[i], 0):\n",
        "            acc += 1.\n",
        "    acc /= num\n",
        "    return acc\n",
        "\n",
        "\n",
        "def compute_avg_log_loss(actual, predicted):\n",
        "    \"\"\"\n",
        "    Computes the average log loss of your predictions.\n",
        "    \"\"\"\n",
        "    num = len(actual)\n",
        "    loss = 0.\n",
        "\n",
        "    for i in range(num):\n",
        "        p = predicted[i] if actual[i] > .5 else 1. - predicted[i]\n",
        "        loss -= math.log(p)\n",
        "    loss /= num\n",
        "    return loss\n",
        "\n",
        "\n",
        "def compute_auroc(actual, predicted):\n",
        "    \"\"\"\n",
        "    Computes the area under the receiver-operator characteristic curve.\n",
        "    This code a rewriting of code by Ben Hamner, available here:\n",
        "    https://github.com/benhamner/Metrics/blob/master/Python/ml_metrics/auc.py\n",
        "    \"\"\"\n",
        "    num = len(actual)\n",
        "    temp = sorted([[predicted[i], actual[i]] for i in range(num)], reverse=True)\n",
        "\n",
        "    sorted_predicted = [row[0] for row in temp]\n",
        "    sorted_actual = [row[1] for row in temp]\n",
        "\n",
        "    sorted_posterior = sorted(zip(sorted_predicted, range(len(sorted_predicted))))\n",
        "    r = [0 for k in sorted_predicted]\n",
        "    cur_val = sorted_posterior[0][0]\n",
        "    last_rank = 0\n",
        "    for i in range(len(sorted_posterior)):\n",
        "        if cur_val != sorted_posterior[i][0]:\n",
        "            cur_val = sorted_posterior[i][0]\n",
        "            for j in range(last_rank, i):\n",
        "                r[sorted_posterior[j][1]] = float(last_rank+1+i)/2.0\n",
        "            last_rank = i\n",
        "        if i==len(sorted_posterior)-1:\n",
        "            for j in range(last_rank, i+1):\n",
        "                r[sorted_posterior[j][1]] = float(last_rank+i+2)/2.0\n",
        "\n",
        "    num_positive = len([0 for x in sorted_actual if x == 1])\n",
        "    num_negative = num - num_positive\n",
        "    sum_positive = sum([r[i] for i in range(len(r)) if sorted_actual[i] == 1])\n",
        "    auroc = ((sum_positive - num_positive * (num_positive + 1) / 2.0) / (num_negative * num_positive))\n",
        "\n",
        "    return auroc\n",
        "\n",
        "\n",
        "def compute_f1(actual, predicted, cutoff = 0.5):\n",
        "    \"\"\"\n",
        "    Computes the F1 score of your predictions. Note that we use 0.5 as the cutoff here.\n",
        "    \"\"\"\n",
        "    num = len(actual)\n",
        "\n",
        "    true_positives = 0\n",
        "    false_positives = 0\n",
        "    false_negatives = 0\n",
        "    true_negatives = 0\n",
        "\n",
        "    for i in range(num):\n",
        "        if actual[i] >= cutoff and predicted[i] >= cutoff:\n",
        "            true_positives += 1\n",
        "        elif actual[i] < cutoff and predicted[i] >= cutoff:\n",
        "            false_positives += 1\n",
        "        elif actual[i] >= cutoff and predicted[i] < cutoff:\n",
        "            false_negatives += 1\n",
        "        else:\n",
        "            true_negatives += 1\n",
        "\n",
        "    try:\n",
        "        precision = true_positives / (true_positives + false_positives)\n",
        "        recall = true_positives / (true_positives + false_negatives)\n",
        "        F1 = 2 * precision * recall / (precision + recall)\n",
        "    except ZeroDivisionError:\n",
        "        F1 = 0.0\n",
        "\n",
        "    return F1\n",
        "\n",
        "\n",
        "def evaluate_metrics(actual, predicted):\n",
        "    \"\"\"\n",
        "    This computes and returns a dictionary of notable evaluation metrics for your predicted labels.\n",
        "    \"\"\"\n",
        "    acc = compute_acc(actual, predicted)\n",
        "    #avg_log_loss = compute_avg_log_loss(actual, predicted)\n",
        "    auroc = compute_auroc(actual, predicted)\n",
        "    F1 = compute_f1(actual, predicted)\n",
        "\n",
        "    return  acc, auroc, F1 #avg_log_loss,  auroc, F1\n",
        "\n",
        "\n",
        "def test_metrics():\n",
        "    actual = [1, 0, 0, 1, 1, 0, 0, 1, 0, 1]\n",
        "    predicted = [0.8, 0.2, 0.6, 0.3, 0.1, 0.2, 0.3, 0.9, 0.2, 0.7]\n",
        "    metrics = evaluate_metrics(actual, predicted)\n",
        "    metrics = {key: round(metrics[key], 3) for key in iterkeys(metrics)}\n",
        "    assert metrics['accuracy'] == 0.700\n",
        "    assert metrics['avglogloss'] == 0.613\n",
        "    assert metrics['auroc'] == 0.740\n",
        "    assert metrics['F1'] == 0.667\n",
        "    print('Verified that our environment is calculating metrics correctly.')"
      ],
      "metadata": {
        "id": "ATRBfOp8Hj5G"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Load Data"
      ],
      "metadata": {
        "id": "_iN_Vd3eSbkD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "training_data, training_labels = load_data(\"/content/en_es/en_es.slam.20190204.train\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pTIRglbADFqW",
        "outputId": "f40e3cd2-05b6-47ca-fce1-5c44049d8116"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading instances...\n",
            "Loaded 317049 instances across 100000 exercises...\n",
            "Loaded 635368 instances across 200000 exercises...\n",
            "Loaded 951536 instances across 300000 exercises...\n",
            "Loaded 1271940 instances across 400000 exercises...\n",
            "Loaded 1591344 instances across 500000 exercises...\n",
            "Loaded 1911212 instances across 600000 exercises...\n",
            "Loaded 2227444 instances across 700000 exercises...\n",
            "Loaded 2546704 instances across 800000 exercises...\n",
            "Done loading 2622957 instances across 824012 exercises.\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "valid_data = load_data(\"/content/en_es/en_es.slam.20190204.dev\")\n",
        "valid_labels = load_labels(\"/content/en_es/en_es.slam.20190204.dev.key\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o56fqfEkzdQO",
        "outputId": "8f4c6444-4a1d-4e83-8eef-d146019ede71"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading instances...\n",
            "Loaded 334439 instances across 100000 exercises...\n",
            "Done loading 387374 instances across 115770 exercises.\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_data = load_data(\"/content/en_es/en_es.slam.20190204.test\")\n",
        "test_labels = load_labels(\"/content/en_es/en_es.slam.20190204.test.key\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-WRh44R3CMOY",
        "outputId": "de6d7b29-c84b-464c-e2d4-793c73e5abc6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading instances...\n",
            "Loaded 337728 instances across 100000 exercises...\n",
            "Done loading 386604 instances across 114586 exercises.\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "min_days = float('inf')\n",
        "max_days = -float('inf')\n",
        "max_time = -float('inf')\n",
        "min_time = float('inf')\n",
        "for instance in training_data:\n",
        "  days = instance.days\n",
        "  time = instance.time\n",
        "  if(time is None or time < 0):\n",
        "    time = 0\n",
        "\n",
        "  if(instance.days > max_days):\n",
        "    max_days = instance.days\n",
        "  if(instance.days < min_days):\n",
        "    min_days = instance.days\n",
        "  if(time > max_time):\n",
        "    max_time = time\n",
        "  if(time < min_time):\n",
        "    min_time = time"
      ],
      "metadata": {
        "id": "wPUAWj46iQD2"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "min_days,max_days,max_time,min_time"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Iiq7_Uugi3sx",
        "outputId": "c6add167-b1d9-4eea-b040-b4685ab085f7"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(0.0, 28.042, 330554, 0)"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Pytorch Datasets"
      ],
      "metadata": {
        "id": "kBfmHACPSfuW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "user_keyed_data = {}\n",
        "user_keyed_label = {}\n",
        "\n",
        "user_idx = 1\n",
        "user2Idx = {\"unk\" : 0}\n",
        "idx2User = {0: \"unk\"}\n",
        "user_vocabulary = [\"unk\"]\n",
        "\n",
        "token_idx = 1\n",
        "word2Idx = {\"unk\" : 0}\n",
        "token_vocabulary = [\"unk\"]\n",
        "\n",
        "\n",
        "pos_idx = 1\n",
        "pos2Idx = {\"unk\" : 0}\n",
        "pos_vocabulary = [\"unk\"]\n",
        "\n",
        "morph_idx = 1\n",
        "morph2Idx = {\"unk\" : 0}\n",
        "morph_vocab = [\"unk\"]\n",
        "\n",
        "dep_label_idx = 1\n",
        "depLabel2Idx = {\"unk\": 0}\n",
        "depLabelVocab = [\"unk\"]"
      ],
      "metadata": {
        "id": "--pQQ-bpuia_"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class ExcerciseDataset(torch.utils.data.Dataset):\n",
        "    def __init__(self, data, labels, sequence_size): \n",
        "        '''\n",
        "        Initializes the dataset.\n",
        "\n",
        "        INPUTS: What inputs do you need here?\n",
        "        '''\n",
        "        global user_idx\n",
        "        global user2Idx\n",
        "        global user_vocabulary\n",
        "\n",
        "        global token_idx\n",
        "        global word2Idx\n",
        "        global token_vocabulary\n",
        "\n",
        "        global pos_idx\n",
        "        global pos2Idx\n",
        "        global pos_vocabulary\n",
        "\n",
        "        global morph_idx\n",
        "        global morph2Idx\n",
        "        global morph_vocab\n",
        "\n",
        "        global dep_label_idx\n",
        "        global depLabel2Idx\n",
        "        global depLabelVocab\n",
        "        \n",
        "        for i, instance in enumerate(data):\n",
        "          user = instance.user\n",
        "          if user not in user_keyed_data:\n",
        "            user_keyed_data[user] = []\n",
        "            user_keyed_label[user] = []\n",
        "          \n",
        "          exercise = []\n",
        "          \n",
        "          \n",
        "          token = instance.token.lower()\n",
        "          pos_tag = instance.part_of_speech.lower()\n",
        "          morphology = instance.morphological_features\n",
        "          dependency_label = instance.dependency_label.lower()\n",
        "          time = instance.time\n",
        "          if time is None or time < 0 or time > 100:\n",
        "            time = 0\n",
        "          days = instance.days\n",
        "          if days is None or days > 100:\n",
        "            days = 0\n",
        "          days = float((days - min_days)/(max_days - min_days))\n",
        "          time = float((time - min_time)/(max_time - min_time))\n",
        "          if(days > 1):\n",
        "            days = 1\n",
        "          if(time > 1):\n",
        "            time = 1\n",
        "\n",
        "          label = labels[instance.instance_id]\n",
        "          \n",
        "          if user not in user2Idx:\n",
        "            user2Idx[user] = user_idx\n",
        "            idx2User[user_idx] = user\n",
        "            user_vocabulary.append(user)\n",
        "            user_idx += 1\n",
        "\n",
        "          exercise.append(user2Idx[user])\n",
        "\n",
        "          if token not in word2Idx:\n",
        "            word2Idx[token] = token_idx\n",
        "            token_vocabulary.append(token)\n",
        "            token_idx += 1\n",
        "\n",
        "          exercise.append(word2Idx[token])\n",
        "\n",
        "          if pos_tag not in pos2Idx:\n",
        "            pos2Idx[pos_tag] = pos_idx\n",
        "            pos_vocabulary.append(pos_tag)\n",
        "            pos_idx += 1\n",
        "\n",
        "          exercise.append(pos2Idx[pos_tag])\n",
        "\n",
        "          # morph_list = []\n",
        "          # for morph_feature in morphology:\n",
        "          #   if morph_feature not in self.morph2Idx:\n",
        "          #     self.morph2Idx[morph_feature] = morph_idx\n",
        "          #     self.morph_vocab.append(morph_feature)\n",
        "          #     morph_idx += 1\n",
        "          #   morph_list.append(self.morph2Idx[morph_feature])\n",
        "          \n",
        "          # exercise.append(morph_list)\n",
        "\n",
        "          if dependency_label not in depLabel2Idx:\n",
        "            depLabel2Idx[dependency_label] = dep_label_idx\n",
        "            depLabelVocab.append(dependency_label)\n",
        "            dep_label_idx += 1\n",
        "\n",
        "          exercise.append(depLabel2Idx[dependency_label])\n",
        "          exercise.append(float(days))\n",
        "          exercise.append(float(time))\n",
        "\n",
        "          user_keyed_data[user].append(torch.tensor(exercise, dtype = float))\n",
        "          user_keyed_label[user].append(label)\n",
        "          \n",
        "\n",
        "        #At this point we have the exercises for each user.\n",
        "\n",
        "        self.timesteped_data = []\n",
        "        self.timesteped_labels = []\n",
        "\n",
        "        #print(self.user_keyed_data[user])\n",
        "\n",
        "        for user in user_keyed_data:\n",
        "          for i in range(0, len(user_keyed_data[user]), 30):\n",
        "            chunk = user_keyed_data[user][i:i + sequence_size]\n",
        "            if(len(chunk) < 2):\n",
        "              continue;\n",
        "            self.timesteped_data.append(torch.stack(chunk,dim=0))\n",
        "            self.timesteped_labels.append(torch.FloatTensor(user_keyed_label[user][i:i + sequence_size]))\n",
        "        \n",
        "        self.length = len(self.timesteped_data)\n",
        "        \n",
        "    def __len__(self):\n",
        "        return self.length\n",
        "\n",
        "    def __getitem__(self, ind):\n",
        "        data = self.timesteped_data[ind] # TODO\n",
        "        labels = self.timesteped_labels[ind] # TODO\n",
        "        return data, labels\n",
        "\n",
        "\n",
        "    def collate_fn(batch):\n",
        "        # batch of input mfcc coefficients\n",
        "        batch_data_encoder = [x[0:len(x)//2] for x,y in batch] # TODO\n",
        "        batch_data_decoder = [x[len(x)//2:] for x,y in batch] # TODO\n",
        "        # batch of output phonemes\n",
        "        batch_labels_encoder = [y[0:len(y)//2] for x,y in batch] # TODO\n",
        "        batch_labels_decoder = [y[len(y)//2:] for x,y in batch] \n",
        "\n",
        "        # HINT: CHECK OUT -> pad_sequence (imported above)\n",
        "        # Also be sure to check the input format (batch_first)\n",
        "        batch_data_encoder_pad = pad_sequence(batch_data_encoder, batch_first=True, padding_value=0) # TODO\n",
        "        batch_data_decoder_pad = pad_sequence(batch_data_decoder, batch_first=True, padding_value=0)\n",
        "\n",
        "        encoder_lengths_data = [len(x) for x in batch_data_encoder] # TODO\n",
        "        decoder_lengths_data = [len(x) for x in batch_data_decoder] \n",
        "\n",
        "        batch_labels_encoder_pad = pad_sequence(batch_labels_encoder, batch_first=True, padding_value=0) # TODO\n",
        "        batch_labels_decoder_pad = pad_sequence(batch_labels_decoder, batch_first=True, padding_value=0)\n",
        "        encoder_lengths_labels =  [len(x) for x in batch_labels_encoder] # TODO\n",
        "        decoder_lengths_labels =  [len(x) for x in batch_labels_decoder] # TODO\n",
        "\n",
        "\n",
        "        # You may apply some transformation, Time and Frequency masking, here in the collate function;\n",
        "        # Food for thought -> Why are we applying the transformation here and not in the __getitem__?\n",
        "        #                  -> Would we apply transformation on the validation set as well?\n",
        "        #                  -> Is the order of axes / dimensions as expected for the transform functions?\n",
        "        \n",
        "        # Return the following values: padded features, padded labels, actual length of features, actual length of the labels\n",
        "        return batch_data_encoder_pad,batch_data_decoder_pad, batch_labels_encoder_pad,batch_labels_decoder_pad, torch.tensor(encoder_lengths_data), torch.tensor(decoder_lengths_data), torch.tensor(encoder_lengths_labels), torch.tensor(decoder_lengths_labels)"
      ],
      "metadata": {
        "id": "v3hHjz3MDKU0"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class ExcerciseValidationDataset(torch.utils.data.Dataset):\n",
        "    def __init__(self, data, labels, sequence_size=128): \n",
        "        '''\n",
        "        Initializes the dataset.\n",
        "\n",
        "        INPUTS: What inputs do you need here?\n",
        "        '''\n",
        "\n",
        "        self.user_keyed_valid_data = {}\n",
        "        self.user_keyed_valid_label = {}\n",
        "        self.sequence_size = sequence_size\n",
        "\n",
        "        global user_idx\n",
        "        global user2Idx\n",
        "        global user_vocabulary\n",
        "\n",
        "        global token_idx\n",
        "        global word2Idx\n",
        "        global token_vocabulary\n",
        "\n",
        "        global pos_idx\n",
        "        global pos2Idx\n",
        "        global pos_vocabulary\n",
        "\n",
        "        global morph_idx\n",
        "        global morph2Idx\n",
        "        global morph_vocab\n",
        "\n",
        "        global dep_label_idx\n",
        "        global depLabel2Idx\n",
        "        global depLabelVocab\n",
        "\n",
        "        \n",
        "        for i, instance in enumerate(data):\n",
        "          user = instance.user\n",
        "          if user not in self.user_keyed_valid_data:\n",
        "            self.user_keyed_valid_data[user] = []\n",
        "            self.user_keyed_valid_label[user] = []\n",
        "          \n",
        "          exercise = []\n",
        "          \n",
        "          \n",
        "          token = instance.token.lower()\n",
        "          pos_tag = instance.part_of_speech.lower()\n",
        "          morphology = instance.morphological_features\n",
        "          dependency_label = instance.dependency_label.lower()\n",
        "          time = instance.time\n",
        "          if time is None:\n",
        "            time = 0\n",
        "          days = instance.days\n",
        "          if days is None:\n",
        "            days = 0\n",
        "          days = float((days - min_days)/(max_days - min_days))\n",
        "          time = float((time - min_time)/(max_time - min_time))\n",
        "          if(days > 1):\n",
        "            print(\"days maxed\")\n",
        "            days = 1\n",
        "          if(time > 1):\n",
        "            print(\"time maxed\")\n",
        "            time = 1\n",
        "\n",
        "          label = labels[instance.instance_id]\n",
        "\n",
        "          assert user in user2Idx\n",
        "          exercise.append(user2Idx[user])\n",
        "\n",
        "          if token not in word2Idx:\n",
        "            token = \"unk\"\n",
        "\n",
        "          exercise.append(word2Idx[token])\n",
        "\n",
        "          if pos_tag not in pos2Idx:\n",
        "            pos_tag = \"unk\"\n",
        "\n",
        "          exercise.append(pos2Idx[pos_tag])\n",
        "\n",
        "          if dependency_label not in depLabel2Idx:\n",
        "            dependency_label = \"unk\"\n",
        "\n",
        "          exercise.append(depLabel2Idx[dependency_label])\n",
        "          exercise.append(float(days))\n",
        "          exercise.append(float(time))\n",
        "\n",
        "          self.user_keyed_valid_data[user].append(torch.tensor(exercise, dtype = float))\n",
        "          self.user_keyed_valid_label[user].append(label)\n",
        "          \n",
        "\n",
        "        #At this point we have the exercises for each user.\n",
        "\n",
        "        self.timesteped_data = []\n",
        "        self.timesteped_labels = []\n",
        "\n",
        "        #print(self.user_keyed_data[user])\n",
        "\n",
        "        for user in self.user_keyed_valid_data:\n",
        "          for i in range(0, len(self.user_keyed_valid_data[user]), sequence_size):\n",
        "            chunk1 = user_keyed_data[user][-sequence_size:] #History for the user\n",
        "            assert len(chunk1) > 0\n",
        "            chunk2 = self.user_keyed_valid_data[user][i:i + sequence_size]\n",
        "            assert len(chunk2) > 0\n",
        "            self.timesteped_data.append(torch.cat((torch.stack(chunk1,dim=0), torch.stack(chunk2,dim=0)), dim=0))\n",
        "            self.timesteped_labels.append(torch.cat(\n",
        "                (torch.FloatTensor(user_keyed_label[user][-sequence_size:]),\n",
        "                torch.FloatTensor(self.user_keyed_valid_label[user][i:i + sequence_size])), \n",
        "                dim = 0\n",
        "                ))\n",
        "        \n",
        "        self.length = len(self.timesteped_data)\n",
        "        \n",
        "    def __len__(self):\n",
        "        return self.length\n",
        "\n",
        "    def __getitem__(self, ind):\n",
        "        data = self.timesteped_data[ind] # TODO\n",
        "        labels = self.timesteped_labels[ind] # TODO\n",
        "        return data, labels\n",
        "\n",
        "\n",
        "    def collate_fn(batch):\n",
        "        # batch of input mfcc coefficients\n",
        "        \n",
        "        batch_data_encoder = [] # TODO\n",
        "        batch_data_decoder = [] # TODO\n",
        "\n",
        "        # batch of output phonemes\n",
        "        batch_labels_encoder = [] # TODO\n",
        "        batch_labels_decoder = [] \n",
        "\n",
        "        for x,y in batch:\n",
        "          user_id =  idx2User[int(x[0][0].item())]\n",
        "          sequence_size = 128\n",
        "          if(len(user_keyed_data[user_id]) < sequence_size):\n",
        "            sequence_size = len(user_keyed_data[user_id])\n",
        "\n",
        "          batch_data_encoder.append(x[0:sequence_size])\n",
        "          assert len(x[0:sequence_size]) > 0\n",
        "          batch_data_decoder.append(x[sequence_size:])\n",
        "          assert len(x[sequence_size:]) > 0\n",
        "          batch_labels_encoder.append(y[0:sequence_size])\n",
        "          assert len(y[0:sequence_size]) > 0\n",
        "          batch_labels_decoder.append(y[sequence_size:])\n",
        "          assert len(y[sequence_size:]) > 0\n",
        "\n",
        "        # HINT: CHECK OUT -> pad_sequence (imported above)\n",
        "        # Also be sure to check the input format (batch_first)\n",
        "        batch_data_encoder_pad = pad_sequence(batch_data_encoder, batch_first=True, padding_value=0) # TODO\n",
        "        batch_data_decoder_pad = pad_sequence(batch_data_decoder, batch_first=True, padding_value=0)\n",
        "\n",
        "        encoder_lengths_data = [len(x) for x in batch_data_encoder] # TODO\n",
        "        decoder_lengths_data = [len(x) for x in batch_data_decoder] \n",
        "\n",
        "        batch_labels_encoder_pad = pad_sequence(batch_labels_encoder, batch_first=True, padding_value=0) # TODO\n",
        "        batch_labels_decoder_pad = pad_sequence(batch_labels_decoder, batch_first=True, padding_value=0)\n",
        "        encoder_lengths_labels =  [len(x) for x in batch_labels_encoder] # TODO\n",
        "        decoder_lengths_labels =  [len(x) for x in batch_labels_decoder] # TODO\n",
        "\n",
        "\n",
        "        # You may apply some transformation, Time and Frequency masking, here in the collate function;\n",
        "        # Food for thought -> Why are we applying the transformation here and not in the __getitem__?\n",
        "        #                  -> Would we apply transformation on the validation set as well?\n",
        "        #                  -> Is the order of axes / dimensions as expected for the transform functions?\n",
        "        \n",
        "        # Return the following values: padded features, padded labels, actual length of features, actual length of the labels\n",
        "        return batch_data_encoder_pad,batch_data_decoder_pad, batch_labels_encoder_pad,batch_labels_decoder_pad, torch.tensor(encoder_lengths_data), torch.tensor(decoder_lengths_data), torch.tensor(encoder_lengths_labels), torch.tensor(decoder_lengths_labels)"
      ],
      "metadata": {
        "id": "C92ufEottsHA"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_data = ExcerciseDataset(training_data, training_labels, 256) #TODO\n",
        "train_loader = torch.utils.data.DataLoader(\n",
        "    dataset     = train_data, \n",
        "    num_workers = 8,\n",
        "    batch_size  = 64, \n",
        "    pin_memory  = True,\n",
        "    shuffle     = True,\n",
        "    collate_fn = ExcerciseDataset.collate_fn\n",
        ") #TODO"
      ],
      "metadata": {
        "id": "Hhv8oeQfSlVd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8c024f23-9bd8-43b8-90bf-8f018d3fec63"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/torch/utils/data/dataloader.py:554: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 4, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(_create_warning_msg(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "val_dataset = ExcerciseValidationDataset(valid_data, valid_labels, 128) #TODO"
      ],
      "metadata": {
        "id": "YBA-bYamzxj0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f49793aa-fe03-4429-83af-e4e4051706fb"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "days maxed\n",
            "days maxed\n",
            "days maxed\n",
            "days maxed\n",
            "days maxed\n",
            "days maxed\n",
            "days maxed\n",
            "days maxed\n",
            "days maxed\n",
            "days maxed\n",
            "days maxed\n",
            "days maxed\n",
            "days maxed\n",
            "days maxed\n",
            "days maxed\n",
            "days maxed\n",
            "days maxed\n",
            "days maxed\n",
            "days maxed\n",
            "days maxed\n",
            "days maxed\n",
            "days maxed\n",
            "days maxed\n",
            "days maxed\n",
            "days maxed\n",
            "days maxed\n",
            "days maxed\n",
            "days maxed\n",
            "days maxed\n",
            "days maxed\n",
            "days maxed\n",
            "days maxed\n",
            "days maxed\n",
            "days maxed\n",
            "days maxed\n",
            "days maxed\n",
            "days maxed\n",
            "days maxed\n",
            "days maxed\n",
            "days maxed\n",
            "days maxed\n",
            "days maxed\n",
            "days maxed\n",
            "days maxed\n",
            "days maxed\n",
            "days maxed\n",
            "days maxed\n",
            "days maxed\n",
            "days maxed\n",
            "days maxed\n",
            "days maxed\n",
            "days maxed\n",
            "days maxed\n",
            "days maxed\n",
            "days maxed\n",
            "days maxed\n",
            "days maxed\n",
            "days maxed\n",
            "days maxed\n",
            "days maxed\n",
            "days maxed\n",
            "days maxed\n",
            "days maxed\n",
            "days maxed\n",
            "days maxed\n",
            "days maxed\n",
            "days maxed\n",
            "days maxed\n",
            "days maxed\n",
            "days maxed\n",
            "days maxed\n",
            "days maxed\n",
            "days maxed\n",
            "days maxed\n",
            "days maxed\n",
            "days maxed\n",
            "days maxed\n",
            "days maxed\n",
            "days maxed\n",
            "days maxed\n",
            "days maxed\n",
            "days maxed\n",
            "days maxed\n",
            "days maxed\n",
            "days maxed\n",
            "days maxed\n",
            "days maxed\n",
            "days maxed\n",
            "days maxed\n",
            "days maxed\n",
            "days maxed\n",
            "days maxed\n",
            "days maxed\n",
            "days maxed\n",
            "days maxed\n",
            "days maxed\n",
            "days maxed\n",
            "days maxed\n",
            "days maxed\n",
            "days maxed\n",
            "days maxed\n",
            "days maxed\n",
            "days maxed\n",
            "days maxed\n",
            "days maxed\n",
            "days maxed\n",
            "days maxed\n",
            "days maxed\n",
            "days maxed\n",
            "days maxed\n",
            "days maxed\n",
            "days maxed\n",
            "days maxed\n",
            "days maxed\n",
            "days maxed\n",
            "days maxed\n",
            "days maxed\n",
            "days maxed\n",
            "days maxed\n",
            "days maxed\n",
            "days maxed\n",
            "days maxed\n",
            "days maxed\n",
            "days maxed\n",
            "days maxed\n",
            "days maxed\n",
            "days maxed\n",
            "days maxed\n",
            "days maxed\n",
            "days maxed\n",
            "days maxed\n",
            "days maxed\n",
            "days maxed\n",
            "days maxed\n",
            "days maxed\n",
            "days maxed\n",
            "days maxed\n",
            "days maxed\n",
            "days maxed\n",
            "days maxed\n",
            "days maxed\n",
            "days maxed\n",
            "days maxed\n",
            "days maxed\n",
            "days maxed\n",
            "days maxed\n",
            "days maxed\n",
            "days maxed\n",
            "days maxed\n",
            "days maxed\n",
            "days maxed\n",
            "days maxed\n",
            "days maxed\n",
            "days maxed\n",
            "days maxed\n",
            "days maxed\n",
            "days maxed\n",
            "days maxed\n",
            "days maxed\n",
            "days maxed\n",
            "days maxed\n",
            "days maxed\n",
            "days maxed\n",
            "days maxed\n",
            "days maxed\n",
            "days maxed\n",
            "days maxed\n",
            "days maxed\n",
            "days maxed\n",
            "days maxed\n",
            "days maxed\n",
            "days maxed\n",
            "days maxed\n",
            "days maxed\n",
            "days maxed\n",
            "days maxed\n",
            "days maxed\n",
            "days maxed\n",
            "days maxed\n",
            "days maxed\n",
            "days maxed\n",
            "days maxed\n",
            "days maxed\n",
            "days maxed\n",
            "days maxed\n",
            "days maxed\n",
            "days maxed\n",
            "days maxed\n",
            "days maxed\n",
            "days maxed\n",
            "days maxed\n",
            "days maxed\n",
            "days maxed\n",
            "days maxed\n",
            "days maxed\n",
            "days maxed\n",
            "days maxed\n",
            "days maxed\n",
            "days maxed\n",
            "days maxed\n",
            "days maxed\n",
            "days maxed\n",
            "days maxed\n",
            "days maxed\n",
            "days maxed\n",
            "days maxed\n",
            "days maxed\n",
            "days maxed\n",
            "days maxed\n",
            "days maxed\n",
            "days maxed\n",
            "days maxed\n",
            "days maxed\n",
            "days maxed\n",
            "days maxed\n",
            "days maxed\n",
            "days maxed\n",
            "days maxed\n",
            "days maxed\n",
            "days maxed\n",
            "days maxed\n",
            "days maxed\n",
            "days maxed\n",
            "days maxed\n",
            "days maxed\n",
            "days maxed\n",
            "days maxed\n",
            "days maxed\n",
            "days maxed\n",
            "days maxed\n",
            "days maxed\n",
            "days maxed\n",
            "days maxed\n",
            "days maxed\n",
            "days maxed\n",
            "days maxed\n",
            "days maxed\n",
            "days maxed\n",
            "days maxed\n",
            "days maxed\n",
            "days maxed\n",
            "days maxed\n",
            "days maxed\n",
            "days maxed\n",
            "days maxed\n",
            "days maxed\n",
            "days maxed\n",
            "days maxed\n",
            "days maxed\n",
            "days maxed\n",
            "days maxed\n",
            "days maxed\n",
            "days maxed\n",
            "days maxed\n",
            "days maxed\n",
            "days maxed\n",
            "days maxed\n",
            "days maxed\n",
            "days maxed\n",
            "days maxed\n",
            "days maxed\n",
            "days maxed\n",
            "days maxed\n",
            "days maxed\n",
            "days maxed\n",
            "days maxed\n",
            "days maxed\n",
            "days maxed\n",
            "days maxed\n",
            "days maxed\n",
            "days maxed\n",
            "days maxed\n",
            "days maxed\n",
            "days maxed\n",
            "days maxed\n",
            "days maxed\n",
            "days maxed\n",
            "days maxed\n",
            "days maxed\n",
            "days maxed\n",
            "days maxed\n",
            "days maxed\n",
            "days maxed\n",
            "days maxed\n",
            "days maxed\n",
            "days maxed\n",
            "days maxed\n",
            "days maxed\n",
            "days maxed\n",
            "days maxed\n",
            "days maxed\n",
            "days maxed\n",
            "days maxed\n",
            "days maxed\n",
            "days maxed\n",
            "days maxed\n",
            "days maxed\n",
            "days maxed\n",
            "days maxed\n",
            "days maxed\n",
            "days maxed\n",
            "days maxed\n",
            "days maxed\n",
            "days maxed\n",
            "days maxed\n",
            "days maxed\n",
            "days maxed\n",
            "days maxed\n",
            "days maxed\n",
            "days maxed\n",
            "days maxed\n",
            "days maxed\n",
            "days maxed\n",
            "days maxed\n",
            "days maxed\n",
            "days maxed\n",
            "days maxed\n",
            "days maxed\n",
            "days maxed\n",
            "days maxed\n",
            "days maxed\n",
            "days maxed\n",
            "days maxed\n",
            "days maxed\n",
            "days maxed\n",
            "days maxed\n",
            "days maxed\n",
            "days maxed\n",
            "days maxed\n",
            "days maxed\n",
            "days maxed\n",
            "days maxed\n",
            "days maxed\n",
            "days maxed\n",
            "days maxed\n",
            "days maxed\n",
            "days maxed\n",
            "days maxed\n",
            "days maxed\n",
            "days maxed\n",
            "days maxed\n",
            "days maxed\n",
            "days maxed\n",
            "days maxed\n",
            "days maxed\n",
            "days maxed\n",
            "days maxed\n",
            "days maxed\n",
            "days maxed\n",
            "days maxed\n",
            "days maxed\n",
            "days maxed\n",
            "days maxed\n",
            "days maxed\n",
            "days maxed\n",
            "days maxed\n",
            "days maxed\n",
            "days maxed\n",
            "days maxed\n",
            "days maxed\n",
            "days maxed\n",
            "days maxed\n",
            "days maxed\n",
            "days maxed\n",
            "days maxed\n",
            "days maxed\n",
            "days maxed\n",
            "days maxed\n",
            "days maxed\n",
            "days maxed\n",
            "days maxed\n",
            "days maxed\n",
            "days maxed\n",
            "days maxed\n",
            "days maxed\n",
            "days maxed\n",
            "days maxed\n",
            "days maxed\n",
            "days maxed\n",
            "days maxed\n",
            "days maxed\n",
            "days maxed\n",
            "days maxed\n",
            "days maxed\n",
            "days maxed\n",
            "days maxed\n",
            "days maxed\n",
            "days maxed\n",
            "days maxed\n",
            "days maxed\n",
            "days maxed\n",
            "days maxed\n",
            "days maxed\n",
            "days maxed\n",
            "days maxed\n",
            "days maxed\n",
            "days maxed\n",
            "days maxed\n",
            "days maxed\n",
            "days maxed\n",
            "days maxed\n",
            "days maxed\n",
            "days maxed\n",
            "days maxed\n",
            "days maxed\n",
            "days maxed\n",
            "days maxed\n",
            "days maxed\n",
            "days maxed\n",
            "days maxed\n",
            "days maxed\n",
            "days maxed\n",
            "days maxed\n",
            "days maxed\n",
            "days maxed\n",
            "days maxed\n",
            "days maxed\n",
            "days maxed\n",
            "days maxed\n",
            "days maxed\n",
            "days maxed\n",
            "days maxed\n",
            "days maxed\n",
            "days maxed\n",
            "days maxed\n",
            "days maxed\n",
            "days maxed\n",
            "days maxed\n",
            "days maxed\n",
            "days maxed\n",
            "days maxed\n",
            "days maxed\n",
            "days maxed\n",
            "days maxed\n",
            "days maxed\n",
            "days maxed\n",
            "days maxed\n",
            "days maxed\n",
            "days maxed\n",
            "days maxed\n",
            "days maxed\n",
            "days maxed\n",
            "days maxed\n",
            "days maxed\n",
            "days maxed\n",
            "days maxed\n",
            "days maxed\n",
            "days maxed\n",
            "days maxed\n",
            "days maxed\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "val_loader = torch.utils.data.DataLoader(\n",
        "    dataset     = val_dataset, \n",
        "    num_workers = 8,\n",
        "    batch_size  = 64, \n",
        "    pin_memory  = True,\n",
        "    shuffle     = True,\n",
        "    collate_fn = ExcerciseValidationDataset.collate_fn\n",
        ") #TODO"
      ],
      "metadata": {
        "id": "T8XCncrfCWx1"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# sanity check\n",
        "i = 0;\n",
        "\n",
        "for data in val_loader:\n",
        "    x_encoder,x_decoder, y_encoder,y_decoder, lx_encoder,lx_decoder, ly_encoder, ly_decoder = data\n",
        "    print(x_encoder.shape,x_decoder.shape, y_encoder.shape,y_decoder.shape, lx_encoder.shape, lx_decoder.shape,ly_encoder.shape, ly_decoder.shape)\n",
        "    i += 1\n",
        "    if(i==2):\n",
        "      break "
      ],
      "metadata": {
        "id": "uk8Ef2mRT8Hh",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6147a60f-a85b-478c-8093-f5d95dc3bb30"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([64, 128, 6]) torch.Size([64, 128, 6]) torch.Size([64, 128]) torch.Size([64, 128]) torch.Size([64]) torch.Size([64]) torch.Size([64]) torch.Size([64])\n",
            "torch.Size([64, 128, 6]) torch.Size([64, 128, 6]) torch.Size([64, 128]) torch.Size([64, 128]) torch.Size([64]) torch.Size([64]) torch.Size([64]) torch.Size([64])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Encoder"
      ],
      "metadata": {
        "id": "0f6KdPmUa3cW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Prepare GloVe for encoder\n",
        "matrix_len = len(token_vocabulary)\n",
        "weights_matrix = np.zeros((matrix_len, 50))\n",
        "words_found = 0\n",
        "\n",
        "for i, word in enumerate(token_vocabulary):\n",
        "    try: \n",
        "        weights_matrix[i] = word2vec[word]\n",
        "        words_found += 1\n",
        "    except KeyError:\n",
        "      if(i == 0):\n",
        "        print(\"here\")\n",
        "        weights_matrix[i] = np.zeros((50, ))\n",
        "      else:\n",
        "        weights_matrix[i] = np.random.normal(scale=0.6, size=(50, ))"
      ],
      "metadata": {
        "id": "auNs8M_OreWj"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Encoder(torch.nn.Module):\n",
        "    '''\n",
        "    The Encoder takes utterances as inputs and returns latent feature representations\n",
        "    '''\n",
        "    def __init__(self, token_embedding_weight_matrix, encoder_hidden_size):\n",
        "        super(Encoder, self).__init__()\n",
        "\n",
        "        self.user_embedding = torch.nn.Embedding(len(user_vocabulary), 10)\n",
        "        self.token_embedding = torch.nn.Embedding(len(token_vocabulary), 15)\n",
        "        #self.token_embedding.load_state_dict({'weight': torch.as_tensor(token_embedding_weight_matrix, dtype=float)})\n",
        "        #self.token_embedding.weight.requires_grad = True\n",
        "\n",
        "        self.pos_embedding = torch.nn.Embedding(len(pos_vocabulary), 10)\n",
        "        self.dependency_embedding = torch.nn.Embedding(len(depLabelVocab), 10)\n",
        "        self.label_embedding = torch.nn.Embedding(2, 10)\n",
        "\n",
        "        self.lstm1 = torch.nn.LSTM(input_size = 57, hidden_size = encoder_hidden_size, num_layers = 2, bidirectional = True, batch_first = True, dropout = 0.1)\n",
        "\n",
        "    def forward(self, x, x_lens, labels):\n",
        "        # Where are x and x_lens coming from? The dataloader\n",
        "        #TODO: Call the embedding layer\n",
        "        with torch.cuda.amp.autocast():\n",
        "          user_embeddings = self.user_embedding(x[:,:,0].clone().detach().to(torch.int64))\n",
        "          token_embeddings = self.token_embedding(x[:,:,1].clone().detach().to(torch.int64))\n",
        "          pos_embeddings = self.pos_embedding(x[:,:,2].clone().detach().to(torch.int64))\n",
        "          dependency_embeddings = self.dependency_embedding(x[:,:,3].clone().detach().to(torch.int64))\n",
        "          label_embeddings = self.label_embedding(labels.clone().detach().to(torch.int64))\n",
        "\n",
        "          concatenated_out = torch.cat((\n",
        "              user_embeddings.clone().detach().to(torch.float),\n",
        "              token_embeddings.clone().detach().to(torch.float),\n",
        "              pos_embeddings.clone().detach().to(torch.float),\n",
        "              dependency_embeddings.clone().detach().to(torch.float),\n",
        "              x[:,:,4].reshape(x[:,:,4].shape[0], x[:,:,4].shape[1], 1).clone().detach().to(torch.float),\n",
        "              x[:,:,5].reshape(x[:,:,5].shape[0], x[:,:,5].shape[1], 1).clone().detach().to(torch.float), \n",
        "              label_embeddings.clone().detach().to(torch.float)), dim=2)\n",
        "        \n",
        "          packed_out = pack_padded_sequence(concatenated_out, x_lens, batch_first = True, enforce_sorted=False)\n",
        "          out = self.lstm1(packed_out)[0]\n",
        "          #out = self.pBLSTMs(out)\n",
        "          # TODO: Pad Packed Sequence\n",
        "          encoder_outputs, encoder_lens = pad_packed_sequence(out, batch_first = True)\n",
        "          \n",
        "          # Remember the number of output(s) each function returns\n",
        "\n",
        "        return encoder_outputs, encoder_lens"
      ],
      "metadata": {
        "id": "Eyg8grmfa4Nz"
      },
      "execution_count": 102,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "encoder = Encoder(weights_matrix, 16)"
      ],
      "metadata": {
        "id": "FCT3SO9zv5y8"
      },
      "execution_count": 58,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for i, data in enumerate(val_loader):\n",
        "  x_encoder,x_decoder, y_encoder,y_decoder, lx_encoder,lx_decoder, ly_encoder, ly_decoder = data\n",
        "  print(type((x_encoder[:,:,3].reshape(x_encoder[:,:,3].shape[0], x_encoder[:,:,3].shape[1], 1)[0,0].item())))\n",
        "  encoder_outputs, encoder_lens = encoder(x_encoder, lx_encoder, y_encoder)\n",
        "  print(encoder_outputs.shape)\n",
        "  break\n",
        "  # encoder_out_new = torch.zeros((encoder_outputs.shape[0], encoder_outputs.shape[2]))\n",
        "  # for batch_output_index in range(encoder_outputs.shape[0]):\n",
        "  #   encoder_out_new[batch_output_index] = torch.sum(encoder_outputs[batch_output_index,0:encoder_lens[batch_output_index]], dim = 0)\n",
        "  # print(encoder_out_new.shape)\n",
        "  #print(torch.sum(encoder_outputs[:,:encoder_lens], dim = 1).shape)"
      ],
      "metadata": {
        "id": "VcIDPxQswThA",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "73766f99-3c41-4344-ffe8-59a3d0e9a4a5"
      },
      "execution_count": 69,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'float'>\n",
            "torch.Size([64, 4639, 32])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Decoder"
      ],
      "metadata": {
        "id": "qfqfTmfuyX6q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class PermuteBlock(torch.nn.Module):\n",
        "    def forward(self, x):\n",
        "        return x.transpose(1, 2)"
      ],
      "metadata": {
        "id": "BFGjV5ElSdPs"
      },
      "execution_count": 103,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Decoder(torch.nn.Module):\n",
        "\n",
        "    def __init__(self,token_embedding_weight_matrix, decoder_hidden_size, output_size = 1):\n",
        "        super().__init__()\n",
        "\n",
        "        self.user_embedding = torch.nn.Embedding(len(user_vocabulary), 10)\n",
        "        self.token_embedding = torch.nn.Embedding(len(token_vocabulary), 15)\n",
        "        #self.token_embedding.load_state_dict({'weight': torch.as_tensor(token_embedding_weight_matrix)})\n",
        "        #self.token_embedding.weight.requires_grad = True\n",
        "\n",
        "        self.pos_embedding = torch.nn.Embedding(len(pos_vocabulary), 10)\n",
        "        self.dependency_embedding = torch.nn.Embedding(len(depLabelVocab), 10)\n",
        "\n",
        "        self.lstm1 = torch.nn.GRU(input_size = 47, hidden_size = decoder_hidden_size, num_layers = 2, bidirectional = True, batch_first = True, dropout = 0.1)\n",
        "        self.mlp_size = 2*decoder_hidden_size + decoder_hidden_size\n",
        "        self.mlp = torch.nn.Sequential(\n",
        "            PermuteBlock(), \n",
        "            torch.nn.BatchNorm1d(self.mlp_size), \n",
        "            PermuteBlock(),\n",
        "\n",
        "            torch.nn.Linear(self.mlp_size, self.mlp_size//2),\n",
        "            PermuteBlock(), \n",
        "            torch.nn.BatchNorm1d(self.mlp_size//2), \n",
        "            PermuteBlock(),\n",
        "            torch.nn.GELU(),\n",
        "            torch.nn.Dropout(p = 0.1),\n",
        "\n",
        "            torch.nn.Linear(self.mlp_size//2, self.mlp_size//4),\n",
        "            PermuteBlock(), \n",
        "            torch.nn.BatchNorm1d(self.mlp_size//4), \n",
        "            PermuteBlock(),\n",
        "            torch.nn.GELU(),\n",
        "            torch.nn.Dropout(p = 0.1),\n",
        "\n",
        "            torch.nn.Linear(self.mlp_size//4, self.mlp_size//8),\n",
        "            PermuteBlock(), \n",
        "            torch.nn.BatchNorm1d(self.mlp_size//8), \n",
        "            PermuteBlock(),\n",
        "            torch.nn.GELU(),\n",
        "            torch.nn.Dropout(p = 0.1),\n",
        "\n",
        "            torch.nn.Linear(self.mlp_size//8, output_size)#,\n",
        "\n",
        "            #torch.nn.Sigmoid()\n",
        "        )\n",
        "        \n",
        "        #self.sigmoid = torch.nn.Sigmoid(dim=2)\n",
        "\n",
        "    def forward(self, encoder_out, x, x_lens):\n",
        "        #TODO call your MLP\n",
        "        #TODO Think what should be the final output of the decoder for the classification \n",
        "\n",
        "        #Assuming encoder_out is of size BatchSize, H_out\n",
        "        user_embeddings = self.user_embedding(x[:,:,0].clone().detach().to(torch.int64))\n",
        "        token_embeddings = self.token_embedding(x[:,:,1].clone().detach().to(torch.int64))\n",
        "        pos_embeddings = self.pos_embedding(x[:,:,2].clone().detach().to(torch.int64))\n",
        "        dependency_embeddings = self.dependency_embedding(x[:,:,3].clone().detach().to(torch.int64))\n",
        "\n",
        "        concatenated_out = torch.cat((\n",
        "            user_embeddings.clone().detach().to(torch.float),\n",
        "            token_embeddings.clone().detach().to(torch.float),\n",
        "            pos_embeddings.clone().detach().to(torch.float),\n",
        "            dependency_embeddings.clone().detach().to(torch.float),\n",
        "            x[:,:,4].reshape(x[:,:,4].shape[0], x[:,:,4].shape[1], 1).clone().detach().to(torch.float),\n",
        "            x[:,:,5].reshape(x[:,:,5].shape[0], x[:,:,5].shape[1], 1).clone().detach().to(torch.float)), dim=2)\n",
        "\n",
        "        packed_out = pack_padded_sequence(concatenated_out, x_lens, batch_first = True, enforce_sorted=False)\n",
        "\n",
        "        out = self.lstm1(packed_out)[0]\n",
        "        decoder_output, decoder_lens = pad_packed_sequence(out, batch_first = True)\n",
        "\n",
        "        out = self.mlp(torch.cat((decoder_output, encoder_out.reshape(encoder_out.shape[0],1, encoder_out.shape[1]).repeat(1,decoder_output.shape[1],1)), dim = 2))\n",
        "        return out.reshape(out.shape[0],out.shape[1])"
      ],
      "metadata": {
        "id": "KZaLH8b2yaNd"
      },
      "execution_count": 107,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "decoder = Decoder(weights_matrix, 32, 1)"
      ],
      "metadata": {
        "id": "nGEZtrWrb8DZ"
      },
      "execution_count": 105,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for i, data in enumerate(val_loader):\n",
        "  x_encoder,x_decoder,y_encoder,y_decoder,lx_encoder,lx_decoder, ly_encoder, ly_decoder = data\n",
        "  print(x_encoder,x_decoder,y_encoder,y_decoder,lx_encoder,lx_decoder, ly_encoder, ly_decoder)\n",
        "\n",
        "  #print(encoder(x_encoder, lx_encoder, y_encoder)[0].shape)\n",
        "  encoder_out, encoder_lens = encoder(x_encoder, lx_encoder, y_encoder)\n",
        "\n",
        "  encoder_out_new = torch.zeros((encoder_out.shape[0], encoder_out.shape[2]))\n",
        "\n",
        "  for batch_output_index in range(encoder_out.shape[0]):\n",
        "    encoder_out_new[batch_output_index] = torch.sum(encoder_out[batch_output_index,0:encoder_lens[batch_output_index]], dim = 0)\n",
        "\n",
        "  decoder_out  = decoder(encoder_out_new, x_decoder, lx_decoder)\n",
        "  print(decoder_out.shape)\n",
        "  break"
      ],
      "metadata": {
        "id": "bte7OsxDUR_8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "dfb835d8-e022-414e-bb2b-61636185e13f"
      },
      "execution_count": 108,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[[2.0680e+03, 1.5400e+02, 4.0000e+00, 4.0000e+00, 7.1543e-01,\n",
            "          1.5126e-05],\n",
            "         [2.0680e+03, 1.1000e+01, 1.0000e+00, 1.0000e+00, 7.1543e-01,\n",
            "          2.4202e-05],\n",
            "         [2.0680e+03, 9.0000e+00, 2.0000e+00, 2.0000e+00, 7.1543e-01,\n",
            "          2.4202e-05],\n",
            "         ...,\n",
            "         [2.0680e+03, 4.6100e+02, 4.0000e+00, 4.0000e+00, 7.4831e-01,\n",
            "          2.1177e-05],\n",
            "         [2.0680e+03, 7.8000e+01, 3.0000e+00, 3.0000e+00, 7.4831e-01,\n",
            "          1.8151e-05],\n",
            "         [2.0680e+03, 1.2090e+03, 4.0000e+00, 4.0000e+00, 7.4831e-01,\n",
            "          1.8151e-05]],\n",
            "\n",
            "        [[6.5200e+02, 7.8000e+01, 3.0000e+00, 3.0000e+00, 5.3809e-01,\n",
            "          8.1681e-05],\n",
            "         [6.5200e+02, 1.8500e+02, 4.0000e+00, 1.0000e+00, 5.3809e-01,\n",
            "          8.1681e-05],\n",
            "         [6.5200e+02, 9.0000e+00, 2.0000e+00, 2.0000e+00, 5.3809e-01,\n",
            "          8.1681e-05],\n",
            "         ...,\n",
            "         [6.5200e+02, 7.1800e+02, 4.0000e+00, 4.0000e+00, 6.7709e-01,\n",
            "          2.5714e-04],\n",
            "         [6.5200e+02, 2.9000e+01, 8.0000e+00, 1.1000e+01, 6.7709e-01,\n",
            "          9.0757e-06],\n",
            "         [6.5200e+02, 3.2100e+02, 4.0000e+00, 4.0000e+00, 6.7709e-01,\n",
            "          9.0757e-06]],\n",
            "\n",
            "        [[1.3980e+03, 3.1000e+01, 9.0000e+00, 1.2000e+01, 6.4057e-01,\n",
            "          4.8404e-05],\n",
            "         [1.3980e+03, 1.9800e+02, 4.0000e+00, 1.3000e+01, 6.4057e-01,\n",
            "          4.8404e-05],\n",
            "         [1.3980e+03, 3.6000e+01, 2.0000e+00, 2.0000e+00, 6.4057e-01,\n",
            "          4.8404e-05],\n",
            "         ...,\n",
            "         [1.3980e+03, 8.4000e+01, 2.0000e+00, 4.0000e+00, 7.1232e-01,\n",
            "          5.4454e-05],\n",
            "         [1.3980e+03, 7.0000e+00, 1.0000e+00, 6.0000e+00, 7.1232e-01,\n",
            "          5.4454e-05],\n",
            "         [1.3980e+03, 3.4500e+02, 4.0000e+00, 7.0000e+00, 7.1232e-01,\n",
            "          5.4454e-05]],\n",
            "\n",
            "        ...,\n",
            "\n",
            "        [[1.7610e+03, 1.5800e+02, 2.0000e+00, 4.0000e+00, 2.5287e-01,\n",
            "          9.3782e-05],\n",
            "         [1.7610e+03, 4.3100e+02, 7.0000e+00, 8.0000e+00, 2.5287e-01,\n",
            "          9.3782e-05],\n",
            "         [1.7610e+03, 4.0700e+02, 7.0000e+00, 4.0000e+00, 2.5287e-01,\n",
            "          9.0757e-06],\n",
            "         ...,\n",
            "         [1.7610e+03, 5.3000e+02, 4.0000e+00, 4.0000e+00, 2.5986e-01,\n",
            "          9.9832e-05],\n",
            "         [1.7610e+03, 7.8000e+01, 3.0000e+00, 3.0000e+00, 2.5986e-01,\n",
            "          3.0252e-06],\n",
            "         [1.7610e+03, 6.2300e+02, 4.0000e+00, 4.0000e+00, 2.5986e-01,\n",
            "          3.0252e-06]],\n",
            "\n",
            "        [[8.9400e+02, 1.0000e+00, 1.0000e+00, 1.0000e+00, 6.5598e-01,\n",
            "          4.5378e-05],\n",
            "         [8.9400e+02, 2.0000e+00, 2.0000e+00, 2.0000e+00, 6.5598e-01,\n",
            "          4.5378e-05],\n",
            "         [8.9400e+02, 1.9000e+01, 8.0000e+00, 4.0000e+00, 6.5598e-01,\n",
            "          4.5378e-05],\n",
            "         ...,\n",
            "         [8.9400e+02, 3.7000e+01, 1.0000e+00, 1.0000e+00, 6.9193e-01,\n",
            "          6.0504e-05],\n",
            "         [8.9400e+02, 5.0000e+01, 2.0000e+00, 4.0000e+00, 6.9193e-01,\n",
            "          6.0504e-05],\n",
            "         [8.9400e+02, 6.7900e+02, 4.0000e+00, 7.0000e+00, 6.9193e-01,\n",
            "          6.0504e-05]],\n",
            "\n",
            "        [[2.5530e+03, 1.0000e+00, 1.0000e+00, 1.0000e+00, 1.1319e-01,\n",
            "          9.0757e-06],\n",
            "         [2.5530e+03, 7.4700e+02, 2.0000e+00, 4.0000e+00, 1.1319e-01,\n",
            "          9.0757e-06],\n",
            "         [2.5530e+03, 1.6000e+01, 7.0000e+00, 4.0000e+00, 1.1333e-01,\n",
            "          2.7227e-05],\n",
            "         ...,\n",
            "         [2.5530e+03, 9.9300e+02, 2.0000e+00, 4.0000e+00, 1.5181e-01,\n",
            "          4.2353e-05],\n",
            "         [2.5530e+03, 7.8000e+01, 3.0000e+00, 3.0000e+00, 1.5181e-01,\n",
            "          4.2353e-05],\n",
            "         [2.5530e+03, 9.9400e+02, 4.0000e+00, 7.0000e+00, 1.5181e-01,\n",
            "          4.2353e-05]]], dtype=torch.float64) tensor([[[2.0680e+03, 3.7000e+01, 1.0000e+00, 7.0000e+00, 8.2105e-01,\n",
            "          5.7479e-05],\n",
            "         [2.0680e+03, 4.3400e+02, 7.0000e+00, 8.0000e+00, 8.2105e-01,\n",
            "          5.7479e-05],\n",
            "         [2.0680e+03, 4.5000e+01, 1.0000e+01, 1.5000e+01, 8.2105e-01,\n",
            "          4.5378e-05],\n",
            "         ...,\n",
            "         [2.0680e+03, 3.0800e+02, 5.0000e+00, 1.0000e+00, 8.5725e-01,\n",
            "          3.3277e-05],\n",
            "         [2.0680e+03, 6.3000e+01, 1.2000e+01, 4.0000e+00, 8.5725e-01,\n",
            "          3.3277e-05],\n",
            "         [2.0680e+03, 4.9000e+01, 2.0000e+00, 4.0000e+00, 8.5725e-01,\n",
            "          1.5126e-05]],\n",
            "\n",
            "        [[6.5200e+02, 5.7000e+01, 5.0000e+00, 5.0000e+00, 6.7752e-01,\n",
            "          1.2101e-05],\n",
            "         [6.5200e+02, 3.2300e+02, 6.0000e+00, 4.0000e+00, 6.7752e-01,\n",
            "          1.2101e-05],\n",
            "         [6.5200e+02, 4.8300e+02, 6.0000e+00, 4.0000e+00, 6.7752e-01,\n",
            "          4.8404e-05],\n",
            "         ...,\n",
            "         [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
            "          0.0000e+00],\n",
            "         [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
            "          0.0000e+00],\n",
            "         [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
            "          0.0000e+00]],\n",
            "\n",
            "        [[1.3980e+03, 6.9000e+01, 1.0000e+00, 1.0000e+00, 7.1265e-01,\n",
            "          2.1177e-05],\n",
            "         [1.3980e+03, 9.0000e+00, 2.0000e+00, 2.0000e+00, 7.1265e-01,\n",
            "          2.1177e-05],\n",
            "         [1.3980e+03, 3.5900e+02, 8.0000e+00, 4.0000e+00, 7.1265e-01,\n",
            "          2.1177e-05],\n",
            "         ...,\n",
            "         [1.3980e+03, 3.8000e+01, 1.0000e+01, 1.5000e+01, 8.1335e-01,\n",
            "          1.8151e-05],\n",
            "         [1.3980e+03, 1.0000e+00, 1.0000e+00, 1.0000e+00, 8.1335e-01,\n",
            "          2.1177e-05],\n",
            "         [1.3980e+03, 2.0000e+00, 1.1000e+01, 1.7000e+01, 8.1335e-01,\n",
            "          2.1177e-05]],\n",
            "\n",
            "        ...,\n",
            "\n",
            "        [[1.7610e+03, 5.7000e+02, 4.0000e+00, 1.0000e+00, 2.6200e-01,\n",
            "          7.5631e-05],\n",
            "         [1.7610e+03, 9.0000e+00, 2.0000e+00, 2.0000e+00, 2.6200e-01,\n",
            "          7.5631e-05],\n",
            "         [1.7610e+03, 2.6700e+02, 8.0000e+00, 4.0000e+00, 2.6200e-01,\n",
            "          7.5631e-05],\n",
            "         ...,\n",
            "         [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
            "          0.0000e+00],\n",
            "         [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
            "          0.0000e+00],\n",
            "         [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
            "          0.0000e+00]],\n",
            "\n",
            "        [[8.9400e+02, 3.6000e+01, 2.0000e+00, 2.0000e+00, 7.8750e-01,\n",
            "          5.4454e-05],\n",
            "         [8.9400e+02, 7.0000e+00, 1.0000e+00, 6.0000e+00, 7.8750e-01,\n",
            "          5.4454e-05],\n",
            "         [8.9400e+02, 3.8600e+02, 4.0000e+00, 4.0000e+00, 7.8750e-01,\n",
            "          5.4454e-05],\n",
            "         ...,\n",
            "         [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
            "          0.0000e+00],\n",
            "         [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
            "          0.0000e+00],\n",
            "         [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
            "          0.0000e+00]],\n",
            "\n",
            "        [[2.5530e+03, 4.2100e+02, 7.0000e+00, 4.0000e+00, 1.8572e-01,\n",
            "          8.7732e-05],\n",
            "         [2.5530e+03, 7.8000e+01, 3.0000e+00, 3.0000e+00, 1.8572e-01,\n",
            "          2.1177e-05],\n",
            "         [2.5530e+03, 1.6400e+02, 4.0000e+00, 1.0000e+00, 1.8572e-01,\n",
            "          2.1177e-05],\n",
            "         ...,\n",
            "         [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
            "          0.0000e+00],\n",
            "         [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
            "          0.0000e+00],\n",
            "         [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
            "          0.0000e+00]]], dtype=torch.float64) tensor([[0., 0., 1.,  ..., 0., 0., 1.],\n",
            "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "        ...,\n",
            "        [0., 1., 0.,  ..., 0., 0., 0.],\n",
            "        [0., 0., 0.,  ..., 0., 1., 1.],\n",
            "        [0., 0., 0.,  ..., 0., 0., 1.]]) tensor([[1., 1., 1.,  ..., 0., 0., 0.],\n",
            "        [0., 0., 1.,  ..., 0., 0., 0.],\n",
            "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
            "        ...,\n",
            "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "        [0., 1., 1.,  ..., 0., 0., 0.],\n",
            "        [0., 1., 1.,  ..., 0., 0., 0.]]) tensor([128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,\n",
            "        128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,\n",
            "        128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,\n",
            "        128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,\n",
            "        128, 128, 128, 128, 128, 128, 128, 128]) tensor([128,  79, 128,  82,  84,  65,  25,  76, 128, 128, 128,  28, 128, 128,\n",
            "         32,  94, 109, 128,  72, 128,  96, 113,   5, 109,  15, 123,  45, 128,\n",
            "        128,  81,  91,  87, 123, 128,  53,  83, 128,  76, 128,  74, 128, 104,\n",
            "         97,  82,  92,  17, 128, 102,  65,  67,  77, 104, 128, 128, 128, 103,\n",
            "        128, 128, 128,  22,  89,  25,  87,  62]) tensor([128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,\n",
            "        128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,\n",
            "        128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,\n",
            "        128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,\n",
            "        128, 128, 128, 128, 128, 128, 128, 128]) tensor([128,  79, 128,  82,  84,  65,  25,  76, 128, 128, 128,  28, 128, 128,\n",
            "         32,  94, 109, 128,  72, 128,  96, 113,   5, 109,  15, 123,  45, 128,\n",
            "        128,  81,  91,  87, 123, 128,  53,  83, 128,  76, 128,  74, 128, 104,\n",
            "         97,  82,  92,  17, 128, 102,  65,  67,  77, 104, 128, 128, 128, 103,\n",
            "        128, 128, 128,  22,  89,  25,  87,  62])\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-108-606b20f274c4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[0mencoder_out_new\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mbatch_output_index\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mencoder_out\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mbatch_output_index\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mencoder_lens\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mbatch_output_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m   \u001b[0mdecoder_out\u001b[0m  \u001b[0;34m=\u001b[0m \u001b[0mdecoder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mencoder_out_new\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx_decoder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlx_decoder\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m   \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdecoder_out\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m   \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1192\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1193\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1194\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1195\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1196\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-104-ba24f3faa3f9>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, encoder_out, x, x_lens)\u001b[0m\n\u001b[1;32m     67\u001b[0m         \u001b[0mpacked_out\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpack_padded_sequence\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconcatenated_out\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx_lens\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_first\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0menforce_sorted\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     68\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 69\u001b[0;31m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlstm1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpacked_out\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     70\u001b[0m         \u001b[0mdecoder_output\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdecoder_lens\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpad_packed_sequence\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_first\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     71\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1192\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1193\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1194\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1195\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1196\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/torch/nn/modules/rnn.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input, hx)\u001b[0m\n\u001b[1;32m    951\u001b[0m             \u001b[0mhx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpermute_hidden\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msorted_indices\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    952\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 953\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcheck_forward_args\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_sizes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    954\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mbatch_sizes\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    955\u001b[0m             result = _VF.gru(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/torch/nn/modules/rnn.py\u001b[0m in \u001b[0;36mcheck_forward_args\u001b[0;34m(self, input, hidden, batch_sizes)\u001b[0m\n\u001b[1;32m    232\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    233\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mcheck_forward_args\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhidden\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_sizes\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mOptional\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 234\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcheck_input\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_sizes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    235\u001b[0m         \u001b[0mexpected_hidden_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_expected_hidden_size\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_sizes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    236\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/torch/nn/modules/rnn.py\u001b[0m in \u001b[0;36mcheck_input\u001b[0;34m(self, input, batch_sizes)\u001b[0m\n\u001b[1;32m    208\u001b[0m                     expected_input_dim, input.dim()))\n\u001b[1;32m    209\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minput_size\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 210\u001b[0;31m             raise RuntimeError(\n\u001b[0m\u001b[1;32m    211\u001b[0m                 'input.size(-1) must be equal to input_size. Expected {}, got {}'.format(\n\u001b[1;32m    212\u001b[0m                     self.input_size, input.size(-1)))\n",
            "\u001b[0;31mRuntimeError\u001b[0m: input.size(-1) must be equal to input_size. Expected 56, got 47"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Complete Model"
      ],
      "metadata": {
        "id": "_XyYTj7JWUab"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class KnowledgeModel(torch.nn.Module):\n",
        "\n",
        "    def __init__(self, embed_size=128, output_size=1):\n",
        "        super().__init__()\n",
        "\n",
        "        #Prepare GloVe for encoder\n",
        "        matrix_len = len(token_vocabulary)\n",
        "        weights_matrix = np.zeros((matrix_len, 50))\n",
        "        words_found = 0\n",
        "\n",
        "        for i, word in enumerate(token_vocabulary):\n",
        "          try: \n",
        "              weights_matrix[i] = word2vec[word]\n",
        "              words_found += 1\n",
        "          except KeyError:\n",
        "            if(i == 0):\n",
        "              weights_matrix[i] = np.zeros((50, ))\n",
        "            else:\n",
        "              weights_matrix[i] = np.random.normal(scale=0.6, size=(50, ))\n",
        "\n",
        "        self.encoder        = Encoder(weights_matrix, embed_size) # TODO: Initialize Encoder\n",
        "        self.decoder        = Decoder(weights_matrix, 2*embed_size, output_size) # TODO: Initialize Decoder \n",
        "    \n",
        "    def forward(self, x_encoder,x_encoder_lengths, y_encoder_labels, x_decoder, x_decoder_lengths):\n",
        "        encoder_out, encoder_lens = self.encoder(x_encoder, x_encoder_lengths, y_encoder_labels)\n",
        "        encoder_out_new = torch.zeros((encoder_out.shape[0], encoder_out.shape[2]))\n",
        "        for batch_output_index in range(encoder_out.shape[0]):\n",
        "          encoder_out_new[batch_output_index] = torch.mean(encoder_out[batch_output_index,0:encoder_lens[batch_output_index]], dim = 0)\n",
        "        #print(encoder_out_new.shape)\n",
        "        encoder_out_new = encoder_out_new.to(device)\n",
        "        decoder_out  = self.decoder(encoder_out_new, x_decoder,  x_decoder_lengths)\n",
        "\n",
        "        return decoder_out"
      ],
      "metadata": {
        "id": "TmFYQO04WVl6"
      },
      "execution_count": 109,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = KnowledgeModel(\n",
        "    embed_size  = 512,\n",
        "    output_size = 1\n",
        ").to(device)\n",
        "print(model)\n",
        "#summary(model,x_encoder.to(device),lx_encoder,y_encoder.to(device), x_decoder.to(device),lx_decoder)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Dg14_QLUrEyD",
        "outputId": "b44b84b4-423a-4391-d094-ae7556df2c65"
      },
      "execution_count": 110,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "KnowledgeModel(\n",
            "  (encoder): Encoder(\n",
            "    (user_embedding): Embedding(2594, 10)\n",
            "    (token_embedding): Embedding(1968, 15)\n",
            "    (pos_embedding): Embedding(17, 10)\n",
            "    (dependency_embedding): Embedding(42, 10)\n",
            "    (label_embedding): Embedding(2, 10)\n",
            "    (lstm1): LSTM(57, 512, num_layers=2, batch_first=True, dropout=0.1, bidirectional=True)\n",
            "  )\n",
            "  (decoder): Decoder(\n",
            "    (user_embedding): Embedding(2594, 10)\n",
            "    (token_embedding): Embedding(1968, 15)\n",
            "    (pos_embedding): Embedding(17, 10)\n",
            "    (dependency_embedding): Embedding(42, 10)\n",
            "    (lstm1): GRU(47, 1024, num_layers=2, batch_first=True, dropout=0.1, bidirectional=True)\n",
            "    (mlp): Sequential(\n",
            "      (0): PermuteBlock()\n",
            "      (1): BatchNorm1d(3072, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (2): PermuteBlock()\n",
            "      (3): Linear(in_features=3072, out_features=1536, bias=True)\n",
            "      (4): PermuteBlock()\n",
            "      (5): BatchNorm1d(1536, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (6): PermuteBlock()\n",
            "      (7): GELU(approximate='none')\n",
            "      (8): Dropout(p=0.1, inplace=False)\n",
            "      (9): Linear(in_features=1536, out_features=768, bias=True)\n",
            "      (10): PermuteBlock()\n",
            "      (11): BatchNorm1d(768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (12): PermuteBlock()\n",
            "      (13): GELU(approximate='none')\n",
            "      (14): Dropout(p=0.1, inplace=False)\n",
            "      (15): Linear(in_features=768, out_features=384, bias=True)\n",
            "      (16): PermuteBlock()\n",
            "      (17): BatchNorm1d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (18): PermuteBlock()\n",
            "      (19): GELU(approximate='none')\n",
            "      (20): Dropout(p=0.1, inplace=False)\n",
            "      (21): Linear(in_features=384, out_features=1, bias=True)\n",
            "    )\n",
            "  )\n",
            ")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Training**"
      ],
      "metadata": {
        "id": "7gpYY89-tnbE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\n",
        "scheduler =  torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, factor=0.5, patience=3, mode='min') # fill this out\n",
        "criterion = torch.nn.BCEWithLogitsLoss(reduction = 'none' ,pos_weight = torch.tensor([10]).to(device))\n",
        "# Mixed Precision, if you need it\n",
        "scaler = torch.cuda.amp.GradScaler()"
      ],
      "metadata": {
        "id": "A_1RvCjDuy03"
      },
      "execution_count": 111,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def create_loss_mask(lens):\n",
        "    mask = torch.arange(max(lens))\n",
        "    mask = torch.tile(mask, (len(lens), 1))\n",
        "    t = torch.tile( lens.reshape((len(lens), 1)) , (1, mask.shape[1]))\n",
        "    mask = mask < t\n",
        "    return mask"
      ],
      "metadata": {
        "id": "Z0U2fr43tpRx"
      },
      "execution_count": 112,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def macro_double_soft_f1(y, y_hat, reduction='mean'): # Written in PyTorch\n",
        "    \"\"\"Compute the macro soft F1-score as a cost (average 1 - soft-F1 across all labels).\n",
        "    Use probability values instead of binary predictions.\n",
        "    This version uses the computation of soft-F1 for both positive and negative class for each label.\n",
        "    Args:\n",
        "        y (torch.FloatTensor): targets array of shape (BATCH_SIZE, N_LABELS), including 0. and 1.\n",
        "        y_hat (torch.FloatTensor): probability matrix from forward propagation of shape (BATCH_SIZE, N_LABELS)\n",
        "    Returns:\n",
        "        cost (scalar): value of the cost function for the batch\n",
        "    \"\"\"\n",
        "\n",
        "    # dtype = y_hat.dtype\n",
        "    # y = y.to(dtype)\n",
        "\n",
        "    # FloatTensor = torch.cuda.FloatTensor\n",
        "    # y = FloatTensor(y)\n",
        "    # y_hat = FloatTensor(y_hat)\n",
        "\n",
        "\n",
        "    tp = (y_hat * y).sum(dim=0) # soft\n",
        "    fp = (y_hat * (1-y)).sum(dim=0) # soft\n",
        "    fn = ((1-y_hat) * y).sum(dim=0) # soft\n",
        "    tn = ((1-y_hat) * (1-y)).sum(dim=0) # soft\n",
        "\n",
        "    soft_f1_class1 = 2*tp / (2*tp + fn + fp + 1e-16)\n",
        "    soft_f1_class0 = 2*tn / (2*tn + fn + fp + 1e-16)\n",
        "    cost_class1 = 1 - soft_f1_class1 # reduce 1 - soft-f1_class1 in order to increase soft-f1 on class 1\n",
        "    cost_class0 = 1 - soft_f1_class0 # reduce 1 - soft-f1_class0 in order to increase soft-f1 on class 0\n",
        "    cost = 0.5 * (cost_class1 + cost_class0) # take into account both class 1 and class 0\n",
        "\n",
        "    if reduction == 'none':\n",
        "        return cost\n",
        "\n",
        "    if reduction == 'mean':\n",
        "        macro_cost = cost.mean()\n",
        "        return macro_cost"
      ],
      "metadata": {
        "id": "XkKMWmuimp4H"
      },
      "execution_count": 113,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tqdm import tqdm\n",
        "\n",
        "def train_model(model, train_loader, criterion, optimizer):\n",
        "    \n",
        "    model.train()\n",
        "    batch_bar = tqdm(total=len(train_loader), dynamic_ncols=True, leave=False, position=0, desc='Train') \n",
        "\n",
        "    total_loss = 0\n",
        "    total_f1 = 0\n",
        "\n",
        "    for i, data in enumerate(train_loader):\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        x_encoder,x_decoder,y_encoder,y_decoder,lx_encoder,lx_decoder, ly_encoder, ly_decoder = data\n",
        "        x_encoder,x_decoder,y_encoder,y_decoder = x_encoder.to(device),x_decoder.to(device),y_encoder.to(device),y_decoder.to(device)\n",
        "        #x, y = x.to(device), y.to(device)\n",
        "\n",
        "        with torch.cuda.amp.autocast():     \n",
        "            decoder_out = model(x_encoder,lx_encoder,y_encoder,x_decoder,lx_decoder)\n",
        "            #print(h.shape)\n",
        "            #print(lh)\n",
        "            loss = criterion(decoder_out, y_decoder)\n",
        "            loss_mask = create_loss_mask(ly_decoder)\n",
        "            loss_mask = loss_mask.to(device)\n",
        "            masked_loss = loss * loss_mask\n",
        "\n",
        "            assert torch.sum(loss_mask) != 0\n",
        "            loss = torch.sum(masked_loss)/torch.sum(loss_mask)\n",
        "\n",
        "\n",
        "        total_loss += loss.item()\n",
        "\n",
        "        batch_bar.set_postfix(\n",
        "            loss=\"{:.04f}\".format(float(total_loss / (i + 1))),\n",
        "            lr=\"{:.06f}\".format(float(optimizer.param_groups[0]['lr'])))\n",
        "\n",
        "        batch_bar.update() # Update tqdm bar\n",
        "\n",
        "        # Another couple things you need for FP16. \n",
        "        scaler.scale(loss).backward() # This is a replacement for loss.backward()\n",
        "        scaler.step(optimizer) # This is a replacement for optimizer.step()\n",
        "        scaler.update() # This is something added just for FP16\n",
        "\n",
        "        del x_encoder,x_decoder,y_encoder,y_decoder,lx_encoder,lx_decoder, ly_encoder, ly_decoder, decoder_out, loss \n",
        "        torch.cuda.empty_cache()\n",
        "\n",
        "    batch_bar.close() # You need this to close the tqdm bar\n",
        "    \n",
        "    return total_loss / len(train_loader)\n",
        "\n",
        "\n",
        "def validate_model(model, val_loader):\n",
        "\n",
        "    model.eval()\n",
        "    batch_bar = tqdm(total=len(val_loader), dynamic_ncols=True, position=0, leave=False, desc='Val')\n",
        "\n",
        "    total_loss = 0\n",
        "    \n",
        "    vdist = 0\n",
        "\n",
        "    for i, data in enumerate(val_loader):\n",
        "\n",
        "        x_encoder,x_decoder,y_encoder,y_decoder,lx_encoder,lx_decoder, ly_encoder, ly_decoder = data\n",
        "        x_encoder,x_decoder,y_encoder,y_decoder = x_encoder.to(device),x_decoder.to(device),y_encoder.to(device),y_decoder.to(device)\n",
        "\n",
        "        #x, y = x.to(device), y.to(device)\n",
        "\n",
        "        with torch.cuda.amp.autocast():   \n",
        "          with torch.inference_mode():\n",
        "              decoder_out = model(x_encoder,lx_encoder,y_encoder,x_decoder,lx_decoder)\n",
        "              #h = torch.permute(h, (1, 0, 2))\n",
        "              loss = criterion(decoder_out, y_decoder)\n",
        "              loss_mask = create_loss_mask(ly_decoder)\n",
        "              loss_mask = loss_mask.to(device)\n",
        "              masked_loss = loss * loss_mask\n",
        "\n",
        "              loss = torch.sum(masked_loss)/torch.sum(loss_mask)\n",
        "\n",
        "        total_loss += float(loss.item())\n",
        "\n",
        "        batch_bar.set_postfix(loss=\"{:.04f}\".format(float(total_loss / (i + 1))), dist=\"{:.04f}\".format(float(vdist / (i + 1))))\n",
        "\n",
        "        batch_bar.update()\n",
        "    \n",
        "        del x_encoder,x_decoder,y_encoder,y_decoder,lx_encoder,lx_decoder, ly_encoder, ly_decoder,decoder_out, loss\n",
        "        torch.cuda.empty_cache()\n",
        "        \n",
        "    batch_bar.close()\n",
        "    total_loss = total_loss/len(val_loader)\n",
        "    return total_loss"
      ],
      "metadata": {
        "id": "1rZhYg8-usp1"
      },
      "execution_count": 114,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_eval_results(model, val_loader):\n",
        "  results = []\n",
        "  sigmoid = torch.nn.Sigmoid()\n",
        "  model.eval()\n",
        "  batch_bar = tqdm(total=len(val_loader), dynamic_ncols=True, position=0, leave=False, desc='Val')\n",
        "  for i, data in enumerate(val_loader):\n",
        "\n",
        "      x_encoder,x_decoder,y_encoder,y_decoder,lx_encoder,lx_decoder, ly_encoder, ly_decoder = data\n",
        "      x_encoder,x_decoder,y_encoder,y_decoder = x_encoder.to(device),x_decoder.to(device),y_encoder.to(device),y_decoder.to(device)\n",
        "\n",
        "      with torch.cuda.amp.autocast(): \n",
        "        with torch.no_grad():\n",
        "            decoder_out = model(x_encoder,lx_encoder,y_encoder,x_decoder,lx_decoder)\n",
        "            decoder_out = sigmoid(decoder_out)\n",
        "\n",
        "      #prediction_string = decode_prediction(h, lh, decoder, PHONEME_MAP=LABELS) # TODO call decode_prediction \n",
        "      #TODO save the output in results array.\n",
        "      i = 0\n",
        "      for out in decoder_out.detach().cpu().numpy():\n",
        "        out1 = out[0:lx_decoder[i]]\n",
        "        results.extend(out1)\n",
        "        i+=1\n",
        "      \n",
        "      del x_encoder,x_decoder,y_encoder,y_decoder,lx_encoder,lx_decoder, ly_encoder, ly_decoder,decoder_out \n",
        "      torch.cuda.empty_cache()\n",
        "      batch_bar.update()\n",
        "  \n",
        "  batch_bar.close()\n",
        "  return results"
      ],
      "metadata": {
        "id": "Hv9wCuJnTDGR"
      },
      "execution_count": 115,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "actual = []\n",
        "for instance_id in iterkeys(valid_labels):\n",
        "  try:\n",
        "      actual.append(valid_labels[instance_id])\n",
        "  except KeyError:\n",
        "      print('No prediction for instance ID ' + instance_id + '!')"
      ],
      "metadata": {
        "id": "tiZTAtBjITbU"
      },
      "execution_count": 116,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "torch.cuda.empty_cache()\n",
        "gc.collect()\n",
        "\n",
        "for epoch in range(0, 50):\n",
        "\n",
        "    print(\"\\nEpoch: {}/{}\".format(epoch+1, 50))\n",
        "    \n",
        "    curr_lr = optimizer.param_groups[0]['lr']\n",
        "\n",
        "    train_loss              = train_model(model, train_loader, criterion, optimizer) \n",
        "    valid_loss  = validate_model(model, val_loader)\n",
        "    val_results = get_eval_results(model, val_loader)\n",
        "    \n",
        "    scheduler.step(valid_loss)\n",
        "\n",
        "    print(\"\\tTrain Loss {:.04f}\\t Learning Rate {:.07f}\".format(train_loss, curr_lr))\n",
        "    print(\"Val Loss {:.04f}\".format(valid_loss))\n",
        "    print(evaluate_metrics(actual, val_results))\n",
        "\n",
        "\n",
        "    # wandb.log({\n",
        "    #     'train_loss': train_loss,  \n",
        "    #     'valid_dist': valid_dist, \n",
        "    #     'valid_loss': valid_loss, \n",
        "    #     'lr'        : curr_lr\n",
        "    # })\n",
        "    \n",
        "#     save_model(model, optimizer, scheduler, ['valid_dist', valid_dist], epoch, epoch_model_path)\n",
        "#     wandb.save(epoch_model_path)\n",
        "#     print(\"Saved epoch model\")\n",
        "\n",
        "#     if valid_dist <= best_lev_dist:\n",
        "#         best_lev_dist = valid_dist\n",
        "#         save_model(model, optimizer, scheduler, ['valid_dist', valid_dist], epoch, best_model_path)\n",
        "#         wandb.save(best_model_path)\n",
        "#         print(\"Saved best model\")\n",
        "#       # You may find it interesting to exlplore Wandb Artifcats to version your models\n",
        "# run.finish()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 978
        },
        "id": "HXoIrQCIwIp_",
        "outputId": "45984a19-b415-427e-89a9-50ee22fbbe94"
      },
      "execution_count": 117,
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            ""
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Epoch: 1/50\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            ""
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\tTrain Loss 1.2265\t Learning Rate 0.0010000\n",
            "Val Loss 1.2848\n",
            "(0.5192578748186507, 0.5058548346376416, 0.22332080064692006)\n",
            "\n",
            "Epoch: 2/50\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            ""
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\tTrain Loss 0.9813\t Learning Rate 0.0010000\n",
            "Val Loss 1.7580\n",
            "(0.5933619706020539, 0.49847163872508576, 0.203963286810428)\n",
            "\n",
            "Epoch: 3/50\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            ""
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\tTrain Loss 0.7367\t Learning Rate 0.0010000\n",
            "Val Loss 2.3813\n",
            "(0.6398416001073898, 0.49977628393473367, 0.1941392152900078)\n",
            "\n",
            "Epoch: 4/50\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            ""
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\tTrain Loss 0.6436\t Learning Rate 0.0010000\n",
            "Val Loss 2.6450\n",
            "(0.6551627109718257, 0.5000939175601892, 0.19021877461972)\n",
            "\n",
            "Epoch: 5/50\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            ""
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\tTrain Loss 0.6412\t Learning Rate 0.0010000\n",
            "Val Loss 2.4277\n",
            "(0.6345082530061388, 0.49891146253325636, 0.19524502227475227)\n",
            "\n",
            "Epoch: 6/50\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\tTrain Loss 0.5210\t Learning Rate 0.0005000\n",
            "Val Loss 3.7230\n",
            "(0.6872892863227785, 0.49857041217505405, 0.17884250474383306)\n",
            "\n",
            "Epoch: 7/50\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Train:  26%|██▌       | 358/1385 [01:29<04:10,  4.09it/s, loss=0.4075, lr=0.000500]"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-117-04bbd1f059c2>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0mcurr_lr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparam_groups\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'lr'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m     \u001b[0mtrain_loss\u001b[0m              \u001b[0;34m=\u001b[0m \u001b[0mtrain_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m     \u001b[0mvalid_loss\u001b[0m  \u001b[0;34m=\u001b[0m \u001b[0mvalidate_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_loader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[0mval_results\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_eval_results\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_loader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-114-86d05572991d>\u001b[0m in \u001b[0;36mtrain_model\u001b[0;34m(model, train_loader, criterion, optimizer)\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mamp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautocast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m             \u001b[0mdecoder_out\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_encoder\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mlx_encoder\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my_encoder\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mx_decoder\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mlx_decoder\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     20\u001b[0m             \u001b[0;31m#print(h.shape)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m             \u001b[0;31m#print(lh)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1192\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1193\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1194\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1195\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1196\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-109-fbc699141de3>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x_encoder, x_encoder_lengths, y_encoder_labels, x_decoder, x_decoder_lengths)\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx_encoder\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mx_encoder_lengths\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_encoder_labels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx_decoder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx_decoder_lengths\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 25\u001b[0;31m         \u001b[0mencoder_out\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencoder_lens\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencoder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_encoder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx_encoder_lengths\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_encoder_labels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     26\u001b[0m         \u001b[0mencoder_out_new\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mencoder_out\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencoder_out\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mbatch_output_index\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mencoder_out\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1192\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1193\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1194\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1195\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1196\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-102-ff1f47033bcf>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x, x_lens, labels)\u001b[0m\n\u001b[1;32m     37\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m           \u001b[0mpacked_out\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpack_padded_sequence\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconcatenated_out\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx_lens\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_first\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0menforce_sorted\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 39\u001b[0;31m           \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlstm1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpacked_out\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     40\u001b[0m           \u001b[0;31m#out = self.pBLSTMs(out)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     41\u001b[0m           \u001b[0;31m# TODO: Pad Packed Sequence\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1192\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1193\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1194\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1195\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1196\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/torch/nn/modules/rnn.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input, hx)\u001b[0m\n\u001b[1;32m    775\u001b[0m                               self.dropout, self.training, self.bidirectional, self.batch_first)\n\u001b[1;32m    776\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 777\u001b[0;31m             result = _VF.lstm(input, batch_sizes, hx, self._flat_weights, self.bias,\n\u001b[0m\u001b[1;32m    778\u001b[0m                               self.num_layers, self.dropout, self.training, self.bidirectional)\n\u001b[1;32m    779\u001b[0m         \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "val_results = get_eval_results(model, val_loader)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oqoGmZ_z1j2s",
        "outputId": "5efceb14-8857-41f8-f014-718185209065"
      },
      "execution_count": 78,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import sys\n",
        "import numpy\n",
        "numpy.set_printoptions(threshold=sys.maxsize)"
      ],
      "metadata": {
        "id": "WqliPm7v0uEy"
      },
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "results = []\n",
        "sigmoid = torch.nn.Sigmoid()\n",
        "model.eval()\n",
        "for data in tqdm(val_loader):\n",
        "\n",
        "    x_encoder,x_decoder,y_encoder,y_decoder,lx_encoder,lx_decoder, ly_encoder, ly_decoder = data\n",
        "    x_encoder,x_decoder,y_encoder,y_decoder = x_encoder.to(device),x_decoder.to(device),y_encoder.to(device),y_decoder.to(device)\n",
        "\n",
        "    with torch.no_grad():\n",
        "        decoder_out = model(x_encoder,lx_encoder,y_encoder,x_decoder,lx_decoder)\n",
        "        decoder_out = sigmoid(decoder_out)\n",
        "\n",
        "    #prediction_string = decode_prediction(h, lh, decoder, PHONEME_MAP=LABELS) # TODO call decode_prediction \n",
        "    #TODO save the output in results array.\n",
        "    i = 0\n",
        "    for out in decoder_out.detach().cpu().numpy():\n",
        "      out1 = out[0:lx_decoder[i]]\n",
        "      results.extend(out1)\n",
        "      i+=1\n",
        "    \n",
        "    del x_encoder,x_decoder,y_encoder,y_decoder,lx_encoder,lx_decoder, ly_encoder, ly_decoder,decoder_out \n",
        "    torch.cuda.empty_cache()"
      ],
      "metadata": {
        "id": "XY7dZG8LDpdC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Extra\n"
      ],
      "metadata": {
        "id": "YhroSFe6IUYV"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Ono8iieGDB10"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# class ExcerciseToken(object):\n",
        "#   def __init__(self, token, id, pos_tag, morphological_features, dep_label, dep_edge_head):\n",
        "#     self.token = token\n",
        "#     self.id = id\n",
        "#     self.pos_tag = pos_tag\n",
        "#     self.morphological_features = morphological_features\n",
        "#     self.dep_label = dep_label\n",
        "#     self.dep_edge_head = dep_edge_head\n",
        "  \n",
        "#   def set_label(self, label):\n",
        "#     self.label = label\n"
      ],
      "metadata": {
        "id": "Sz4qwkzDIT2u"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# class ExcerciseInformation(object):\n",
        "#   def __init__(self):\n",
        "#     self.exercise_tokens = []\n",
        "#     self.prompt = \"\"\n",
        "#     self.user = \"\"\n",
        "#     self.countries = \"\"\n",
        "#     self.days = 0.0\n",
        "#     self.client = \"\"\n",
        "#     self.session = \"\"\n",
        "#     self.format = \"\"\n",
        "#     self.time = 0.0\n",
        "  \n",
        "#   def add_exercise_token(self, excercise_token_info: ExcerciseToken):\n",
        "#     self.exercise_tokens.append(excercise_token_info)\n",
        "  \n",
        "#   def set_prompt(self, prompt: str):\n",
        "#     self.prompt = prompt\n",
        "\n",
        "#   def set_user(self, user: str):\n",
        "#     self.user = user\n",
        "  \n",
        "#   def set_countries(self, countries: str):\n",
        "#     self.countries = countries\n",
        "\n",
        "#   def set_days(self, days: float):\n",
        "#     self.days = days\n",
        "  \n",
        "#   def set_client(self, client: str):\n",
        "#     self.client = client\n",
        "  \n",
        "#   def set_session(self, session: str):\n",
        "#     self.session = session\n",
        "  \n",
        "#   def set_format(self, format: str):\n",
        "#     self.format = format\n",
        "\n",
        "#   def set_time(self, time: float):\n",
        "#     self.time = time\n",
        "  \n",
        "\n"
      ],
      "metadata": {
        "id": "Gxqn_2VPIV_-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "oOQFNQqHf0-C"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}